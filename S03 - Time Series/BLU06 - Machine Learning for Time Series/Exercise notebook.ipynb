{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3db1b7eb6aade580",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# BLU06  - Exercise Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d9b262915f7cb1e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "idx = pd.IndexSlice\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)   \n",
    "from random import seed\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import itertools\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa import stattools\n",
    "import hashlib # for grading purposes\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from pandas.plotting import lag_plot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-efc88f208fd6703c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb6777a76facfe35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "These functions will be necessary for the exercises. The only one you'll use is _predict_n_periods_. The others are used by the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4b3975b136921032",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def build_target(series_, number_of_periods_ahead):\n",
    "    \"\"\" \n",
    "    takes a series, turned it into a dataframe, and adds a new column called target\n",
    "    This column is the input series, lagged number_of_periods_ahead into the future\n",
    "    \"\"\"\n",
    "    \n",
    "    # make a copy \n",
    "    series_ = series_.copy()\n",
    "    series_.name = 'customers'\n",
    "    \n",
    "    # make a dataframe from the series\n",
    "    df_ = pd.DataFrame(series_)\n",
    "    \n",
    "    # the target column will be the input series, lagged into the future\n",
    "    df_['target'] = series_.shift(-number_of_periods_ahead)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-922878325abdd03c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def separate_last_day(df_):\n",
    "    \n",
    "    \"\"\"\n",
    "    takes a dataset which has the target and features built \n",
    "    and separates it into the last day\n",
    "    \"\"\"\n",
    "    # take the last period \n",
    "    last_period = df_.iloc[-1]\n",
    "    \n",
    "    # the last period is now a series, so it's name will be the timestamp\n",
    "    training_data = df_.loc[df_.index < last_period.name]\n",
    "\n",
    "    return last_period, training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-84d68d31545e3063",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def build_some_features(df_, num_periods_lagged=1, num_periods_diffed=0, weekday=False, month=False, rolling=[], holidays=False): \n",
    "    \"\"\"\n",
    "    Builds some features by calculating differences between periods  \n",
    "    \"\"\"\n",
    "    # make a copy \n",
    "    df_ = df_.copy()\n",
    "        \n",
    "    # for a few values, get the lags  \n",
    "    for i in range(1, num_periods_lagged+1):\n",
    "        # make a new feature, with the lags in the observed values column\n",
    "        df_['lagged_%s' % str(i)] = df_['customers'].shift(i)\n",
    "        \n",
    "    # for a few values, get the diffs  \n",
    "    for i in range(1, num_periods_diffed+1):\n",
    "        # make a new feature, with the lags in the observed values column\n",
    "        df_['diff_%s' % str(i)] = df_['customers'].diff(i)\n",
    "    \n",
    "    for stat in rolling:\n",
    "        df_['rolling_%s'%str(stat)] = df_['customers'].rolling('7D').aggregate(stat)\n",
    "        \n",
    "    if weekday == True:\n",
    "        df_['sin_weekday'] = np.sin(2*np.pi*df_.index.weekday/7)\n",
    "        df_['cos_weekday'] = np.sin(2*np.pi*df_.index.weekday/7)\n",
    "        \n",
    "    if month == True:\n",
    "        df_['sin_month'] = np.sin(2*np.pi*df_.index.month/12)\n",
    "        df_['cos_month'] = np.sin(2*np.pi*df_.index.month/12)\n",
    "        \n",
    "    if holidays == True:\n",
    "        holidays = df_[((df_.index.month==12) & (df_.index.day==25))\n",
    "              |((df_.index.month==1) & (df_.index.day==1))].customers\n",
    "        df_['holidays'] = holidays + 1\n",
    "        df_['holidays'] = df_['holidays'].fillna(0)\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f4d816f5cc808636",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def separate_train_and_test_set(last_period_, training_data_, target='target'): \n",
    "    \n",
    "    \"\"\" \n",
    "    separates training and test set (clue was in the name, really... )\n",
    "    Ok, we were lazy and left the target hardcoded as 'target'. Shame on us. \n",
    "    \"\"\"\n",
    "    \n",
    "    # anything that isn't a target is a feature \n",
    "    features = [feature for feature in training_data_.columns if feature != target]\n",
    "    \n",
    "    # adding a sneaky little dropna to avoid the missing data problem above \n",
    "    X_train = training_data_.dropna()[features]\n",
    "    y_train = training_data_.dropna()[target]\n",
    "    \n",
    "    X_last_period = last_period_[features]\n",
    "    \n",
    "    return X_train, y_train, X_last_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bc08afac09669562",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_prediction(series_, number_of_periods_ahead, num_periods_lagged, num_periods_diffed, weekday, month, rolling, holidays):\n",
    "    \n",
    "    \"\"\" \n",
    "    Wrapper to go from the original series to X_train, y_train, X_last_period \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # build the target \n",
    "    data_with_target = build_target(series_, \n",
    "                                    number_of_periods_ahead)\n",
    "    \n",
    "    # build the features \n",
    "    data_with_target_and_features = build_some_features(data_with_target, \n",
    "                                                        num_periods_lagged=num_periods_lagged,\n",
    "                                                       num_periods_diffed=num_periods_diffed,\n",
    "                                                       weekday=weekday,\n",
    "                                                       month=month,\n",
    "                                                       rolling=rolling,\n",
    "                                                       holidays=holidays)\n",
    "    # separate train and test data \n",
    "    last_period, training_data = separate_last_day(data_with_target_and_features)\n",
    "\n",
    "    # separate X_train, y_train, and X_test \n",
    "    X_train, y_train, X_last_period = separate_train_and_test_set(last_period, \n",
    "                                                           training_data, \n",
    "                                                           target='target')\n",
    "    \n",
    "    # return ALL OF THE THINGS! (well, actually just the ones we need)\n",
    "    return X_train, y_train, X_last_period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a743d99c1cb73f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_period_n(series_, model, number_of_periods_ahead, num_periods_lagged, num_periods_diffed, weekday, month, rolling, holidays): \n",
    "    \n",
    "        X_train, y_train, X_last_period = prepare_for_prediction(series_, \n",
    "                                                             number_of_periods_ahead, \n",
    "                                                             num_periods_lagged,\n",
    "                                                             num_periods_diffed,\n",
    "                                                             weekday,\n",
    "                                                             month,\n",
    "                                                             rolling,\n",
    "                                                             holidays)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        return model.predict(X_last_period.values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c4345e87909ae7f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_n_periods(series_, n_periods, model, num_periods_lagged, num_periods_diffed=0, weekday=False, month=False,rolling=[], holidays=False): \n",
    "    predictions = []\n",
    "\n",
    "    for period_ahead in range(1, n_periods+1):\n",
    "        pred = predict_period_n(series_=series_, \n",
    "                                model=model, \n",
    "                                number_of_periods_ahead=period_ahead, \n",
    "                                num_periods_lagged=num_periods_lagged,\n",
    "                                num_periods_diffed=num_periods_diffed,\n",
    "                                weekday=weekday,\n",
    "                                month=month,\n",
    "                                rolling=rolling,\n",
    "                                holidays=holidays)\n",
    "        \n",
    "        predictions.append(pred[0])\n",
    "        \n",
    "    return predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9a3e566cc624451",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Let's predict store customers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c89f8456e9e70392",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "store = pd.read_csv('data/stores_exercise.csv')\n",
    "store['date'] = pd.to_datetime(store['date'])\n",
    "store = store.set_index('date')\n",
    "store = store.sort_index()\n",
    "store = store[:-180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5db0587a41ba75ab",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "##### Plot the series to get an idea of what's going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-846a66e59e645d8e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "store.plot(figsize=(16, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-50c774b21ff04b4b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q1: Are there any missing days in the time series? If so, inspect them and decide how to fill them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4673648012938702",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# hint1: if the missing dates are holidays you can fill them with 0, since that's\n",
    "# indication that the store was closed.\n",
    "\n",
    "# hint2: the missing_value_mask should be a boolean Pandas Series with True or False according to if the value\n",
    "# missing or not.\n",
    "\n",
    "# hint3: the missing_value_dates should be a DatetimeIndex with the dates with missing values.\n",
    "\n",
    "# store_resampled = \n",
    "# missing_value_mask =\n",
    "# missing_value_dates = \n",
    "# store_cleaned = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-37f19bfc31b2d1e0",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'e9f26ecc6d60870d336e555719e6024c19a07e62c9e7174c36c42b847d50936a'\n",
    "assert hashlib.sha256(str(missing_value_dates).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '5ddd3f2573d5c72b9718a3626e6478ec5f7f68f572e36dd3752cb962bf8602a5'\n",
    "assert hashlib.sha256(str(store_cleaned).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef1184e061dcce01",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q2: Formulate it as time series one-step-ahead prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52ebd77841c0b4ce",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q2.1 Create the target, the lags and drop the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b2bfb6431053bbb1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Note: You should add as features the top 5 lags. To do that, look a the ACF of the time series and chose\n",
    "# Remember from the previous BLU to look at the ACF you only need to run plot_acf(store)\n",
    "# the top5 most correlated lags.\n",
    "\n",
    "#store_features = \n",
    "#store_features['lag_a'] = \n",
    "#store_features['lag_b'] = \n",
    "#store_features['lag_c'] = \n",
    "#store_features['lag_d'] = \n",
    "#store_features['lag_e'] = \n",
    "#store_features['target'] =\n",
    "#store_features = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ec83e113b13f6716",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '87d487ce996d6bdbf2f7f919c5c40afc5ab52775f9ddb4798572c3d32e585699'\n",
    "assert hashlib.sha256(str(store_features.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '33f8d758034dda4da49f9060da8a1870a17e39738a0a6c891ed0d76e5dbdff8c'\n",
    "assert hashlib.sha256(str(store_features.iloc[0]).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ab428009d677b3c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q2.2 Separate the training and test set. The test set consists of the last 60 values, while the training set consists of the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0aa5b9495555cd7d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# note: this is a very straightforward question. But you may think: \"isn't this one-step-ahead forecasting? \n",
    "# Why does the test have 60 values\" Well, basically this just means we are doing 60 one-step-ahead forecasts.\n",
    "# This way we obtain a better estimate of how our one-step-ahead model would perform in real life.\n",
    "\n",
    "# store_train =\n",
    "# store_test =\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-46d22f610161d58e",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '0d597dc2afbcf77932523efe4fa118591cbc3f691191c2471ae95e465c918dd3'\n",
    "assert hashlib.sha256(str(store_train.index[-1]).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '23a57d8694a6eb61e0232c384c6939676cf8f8d515298f7f388b9071c22af223'\n",
    "assert hashlib.sha256(str(store_test.index[0]).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-328a6be750d6b545",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q2.3 Fit a linear regression to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c10406518994a44d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# X_store_train = \n",
    "# y_store_train =\n",
    "# model =\n",
    "# model.fit()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ba2d8a4a2f417e25",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'cc02033f738b18730fa0d433c70f9f93d2db69418fd9a7bb1f3d1cd8683313ba'\n",
    "assert hashlib.sha256(str(X_store_train.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '0fabfb9c5d2a657b34aa1ce1474093e522fc2841b3665fdaaabb67e40eddcf44'\n",
    "assert hashlib.sha256(str(y_store_train.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '7624371ed342168f5e33937f92ba58381bb3d29a9a904b0e9e48940649c7e0cf'\n",
    "assert hashlib.sha256(str(np.round(model.coef_,1)).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f91888ec4ca37707",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q2.4 Predict the test set and calculate the MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c702242ee9013f2d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# X_store_test =\n",
    "# y_store_test = \n",
    "# y_predict = \n",
    "# test_mae = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fa53ac00c701b6ad",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'eca663a9d471ccdde2af2ff1aafbb6bb843c6ef5e21bebc2321143a8166971a7'\n",
    "assert hashlib.sha256(str(X_store_test.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '9053d01727f35cfdbbbd7284dba5e54ee557e5fc33084045dbc6fec2cb8730f7'\n",
    "assert hashlib.sha256(str(y_store_test.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '8b940be7fb78aaa6b6567dd7a3987996947460df1c668e698eb92ca77e425349'\n",
    "assert hashlib.sha256(str(np.int(test_mae)).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b64863f837f65e9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q3 Let's go into multi-step prediction!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b8175f4db9400784",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q3.1 Separate the data into train and test. Use the _predict_n_periods_ function to predict 60 steps ahead using linear regression. Then, calculate the MAE for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4e7b5a3887dcbaa",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# hint: use the cleaned dataset\n",
    "# Use 7 lags\n",
    "\n",
    "# store_multistep_train = \n",
    "# store_multistep_test =\n",
    "# predictions = \n",
    "# test_mae = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d64221e5c054b60c",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '299fe0f9c075c40a21029166ce1bd2046db47fcb639a2a13240b5d974961cb0b'\n",
    "assert hashlib.sha256(str(store_multistep_train.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '01f6bb906f864c80f90afb9e7d9071b6f6e7222bf67f2de6bce28f55981fbab4'\n",
    "assert hashlib.sha256(str(store_multistep_test.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = 'f1ee529ef49111208f1c1646c53c8c311c9f093fd7891c1b46d77e98210b018d'\n",
    "assert hashlib.sha256(str(np.int(predictions[-1])).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '29db0c6782dbd5000559ef4d9e953e300e2b479eed26d887ef3f92b921c06a67'\n",
    "assert hashlib.sha256(str(np.int(test_mae)).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6cecdca4023a9b09",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q3.2 Separate into train, val and test. Test corresponds to the last 60 values and Val corresponds to the 60 steps before test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4676deaf08fb5b8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# hint: use the cleaned dataset\n",
    "\n",
    "# store_multistep_train =\n",
    "# store_multistep_val =\n",
    "# store_multistep_test = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-144aa010340df42d",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '98eb165d180aa2cd9255f5a5151c101fac78fba9ce6c24421daa8b64ca2a0288'\n",
    "assert hashlib.sha256(str(store_multistep_train.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '01f6bb906f864c80f90afb9e7d9071b6f6e7222bf67f2de6bce28f55981fbab4'\n",
    "assert hashlib.sha256(str(store_multistep_val.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '01f6bb906f864c80f90afb9e7d9071b6f6e7222bf67f2de6bce28f55981fbab4'\n",
    "assert hashlib.sha256(str(store_multistep_test.shape).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a252157fed7db039",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q3.3 Are the holidays, weekday and the month of the year useful features to the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-16a7b564ac712979",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a parameter grid using the gradient boosting regressor as a model. \n",
    "# Use 5 lags, zero diffs and no rollings\n",
    "# For the gradient boosting regressor use n_estimators=20 and random_state=10\n",
    "# Use a for cycle to find the group of params that minimizes the MAE on the validation set.\n",
    "\n",
    "# hint: to have no rollings in the predict_n_periods you should send an empty lists of lists: [[]]\n",
    "\n",
    "\n",
    "#param_grid = \n",
    "\n",
    "# grid = \n",
    "\n",
    "# for params in grid:\n",
    "     # predictions =\n",
    "                                    \n",
    "# best_params = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-27e82c63c7934897",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '3cbc87c7681f34db4617feaa2c8801931bc5e42d8d0f560e756dd4cd92885f18'\n",
    "assert hashlib.sha256(str(best_params['weekday']).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '3cbc87c7681f34db4617feaa2c8801931bc5e42d8d0f560e756dd4cd92885f18'\n",
    "assert hashlib.sha256(str(best_params['month']).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '3cbc87c7681f34db4617feaa2c8801931bc5e42d8d0f560e756dd4cd92885f18'\n",
    "assert hashlib.sha256(str(best_params['holidays']).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cd3355c62f859eeb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q3.4 Train a model with the best combination and predict the test set. Calculate the corresponding MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8fdbd5c2eaf09dc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# For the gradient boosting regressor use n_estimators=20 and random_state=10\n",
    "# We expect you to train the final model with train and val together.\n",
    "# store_multistep_train_val = \n",
    "# predictions = \n",
    "# test_mae = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cc1f893477248c54",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '434c9b5ae514646bbd91b50032ca579efec8f22bf0b4aac12e65997c418e0dd6'\n",
    "assert hashlib.sha256(str(np.int(test_mae)).encode()).hexdigest() == expected_hash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
