{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b07abb410d0b03e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "# BLU14 - Exercise Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6029358aaa125687",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders\n",
    "import json\n",
    "import joblib\n",
    "import pickle\n",
    "import math\n",
    "import requests\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "from uuid import uuid4\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1e4de53acc49a080",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After the police you nailed another big client. A hospital hired you to try to help predicting if a person is going to suffer from heart disease or not, so they can redirect patients from other appointments into the proper treatment, if needed, minimizing later problems with this. You're no expert in the medical field, but you decide to take on the challenge.\n",
    "\n",
    "<img src=\"media/helth.png\" width=400 />\n",
    "\n",
    "They provide you with a dataset with several patient measures and the fact that they had heart disease or not.\n",
    "\n",
    "They also provide you with the following data description:\n",
    "\n",
    "#### Attribute Information\n",
    "\n",
    "    1) age\n",
    "    2) sex\n",
    "    3) cp - chest pain type (4 values)\n",
    "    4) trestbps - resting blood pressure\n",
    "    5) chol - serum cholesterol in mg/dl\n",
    "    6) fbs - fasting blood sugar > 120 mg/dl\n",
    "    7) restecg - resting electrocardiographic results (values 0,1,2)\n",
    "    8) thalach - maximum heart rate achieved\n",
    "    9) exang - exercise induced angina\n",
    "    10) oldpeak - ST depression induced by exercise relative to rest\n",
    "    11) slope - the slope of the peak exercise ST segment\n",
    "    12) ca - number of major vessels (0-3) colored by fluoroscopy\n",
    "    13) thal - thallium stress test: 0 = normal; 1 = fixed defect; 2 = reversable defect\n",
    "    14) target - 0= less chance of heart attack 1= more chance of heart attack\n",
    "\n",
    "**Note**: even if the dataset has values outside of the data dictionary, you should for these exercises consider the data dictionary as the source truth\n",
    "\n",
    "Load the dataset below and check out its format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-38fc8b0a01b6c17d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\"data\", \"heart.csv\"))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1f0716dd0e185a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's split our data into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3079f4bf5c6b51a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "df_test.target.value_counts().plot(kind=\"bar\");\n",
    "plt.xlabel('Target value');\n",
    "plt.ylabel('Target value counts');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b5a701873eb4a857",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1)  \n",
    "\n",
    "### Q1.a) Train a baseline model\n",
    "\n",
    "Build a baseline model for this problem (don't worry about performance for now) and serialize it. Use the following features:\n",
    "\n",
    "    1) age\n",
    "    2) sex\n",
    "    3) cp - chest pain type (4 values)\n",
    "    4) trestbps - resting blood pressure\n",
    "    6) fbs - fasting blood sugar > 120 mg/dl\n",
    "    7) restecg - resting electrocardiographic results (values 0,1,2)\n",
    "    10) oldpeak - ST depression induced by exercise relative to rest\n",
    "    12) ca - number of major vessels (0-3) colored by fluoroscopy\n",
    "    13) thal - thallium stress test: 0 = normal; 1 = fixed defect; 2 = reversable defect\n",
    "\n",
    "\n",
    "**Note**: As we already provided the split, use the `df_train` to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c0f8bd2fd8a95779",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a temporary directory where your serialized files will be saved. Make sure you use this as \n",
    "# the target folder when you serialize your files\n",
    "TMP_DIR = '/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a8b3cf903220496",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Write code to train and serialize a model in the block below\n",
    "#\n",
    "# Outputs expected: `columns.json`, `dtypes.pickle` and `pipeline.pickle`\n",
    "#\n",
    "# Your pipeline should be able to receive a dataframe with the columns we've requested you to use\n",
    "# in the form `pipeline.predict(test_df)`\n",
    "#\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "list_features = ['age', 'sex', 'cp', 'trestbps', 'fbs', 'restecg', 'oldpeak', 'ca', 'thal'] \n",
    "\n",
    "# for i in list_features:\n",
    "#     print(df_train[i].value_counts(dropna=False))\n",
    "        \n",
    "\n",
    "list_features_cat = ['fbs', 'sex'] \n",
    "\n",
    "target = 'target'\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, list_features_cat)])\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    RandomForestClassifier(max_depth=3, min_samples_leaf=.03, class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    ")\n",
    "\n",
    "X_train = df_train[list_features]\n",
    "y_train = df_train[target]\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "X_test = df_test[list_features]\n",
    "y_test = df_test[target]\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "roc_auc_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Serializing\n",
    "\n",
    "with open('tmp/columns.json', 'w') as fh:\n",
    "    json.dump(X_train.columns.tolist(), fh)\n",
    "    \n",
    "with open('tmp/dtypes.pickle', 'wb') as fh:\n",
    "    pickle.dump(X_train.dtypes, fh)\n",
    "    \n",
    "joblib.dump(pipeline, 'tmp/pipeline.pickle');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your procedure is correct by running the asserts below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-02ebbb63fbd9f79a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(TMP_DIR, 'columns.json')) as fh:\n",
    "    columns = json.load(fh)\n",
    "    assert columns == [\"age\", \"sex\", \"cp\", \"trestbps\", \"fbs\", \"restecg\", \"oldpeak\", \"ca\", \"thal\"]\n",
    "\n",
    "with open(os.path.join(TMP_DIR, 'dtypes.pickle'), 'rb') as fh:\n",
    "    dtypes = pickle.load(fh)\n",
    "    assert dtypes.apply(lambda x: str(x)).isin([\"int64\", \"int32\", \"float64\", \"float32\"]).all()\n",
    "\n",
    "with open(os.path.join(TMP_DIR, 'pipeline.pickle'), 'rb') as fh:\n",
    "    pipeline = joblib.load(fh)\n",
    "    assert isinstance(pipeline, Pipeline)\n",
    "    assert pipeline.predict(pd.DataFrame([{\n",
    "        \"age\": 23, \n",
    "        \"sex\": 1, \n",
    "        \"cp\": 3, \n",
    "        \"trestbps\": 120, \n",
    "        \"fbs\": 1,\n",
    "        \"restecg\": 1,\n",
    "        \"oldpeak\": 0, \n",
    "        \"ca\": 0, \n",
    "        \"thal\": 1}\n",
    "    ], columns=columns).astype(dtypes)) in [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cec5bed529e037b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1.b) Client requirements\n",
    "\n",
    "\n",
    "Now, the doctors asked you one more thing. They want to make sure your model is as good at retrieving male cases of heart disease as it is retrieving female cases. \n",
    "\n",
    "For example, if we have a pool of patients where 100 male patients actually have heart disesase and we retrieve 80 out of those, and where 100 female patients also have heart disesase but we only return 20 from those, then you're discrimating and that's not ok. A similar proportion, such as 75 women out of the 100 with heart disease, is expected.\n",
    "\n",
    "Build a small function to verify this. In particular make sure that the difference in percentage points is not higher than 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0ca5bf28d4e81180",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def verify_retrieve_rates(X_test, y_true, y_test):\n",
    "    \"\"\"\n",
    "    Verify retrieval rates for different `sex` instances are \n",
    "    not different by more than 5 percentage points\n",
    "    \n",
    "    Inputs:\n",
    "        X_test: features for the test cases\n",
    "        y_true: true labels for the test cases [0, 1]\n",
    "        y_test: predictions for the test cases [0, 1]\n",
    "\n",
    "    Returns: tuple of (success, rate_difference)\n",
    "        success: True if the condition is satisfied, otherwise False\n",
    "        rate_difference: difference between each class retrieval rates (as an absolute value) \n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "        \n",
    "    mask_0 = X_test['sex'] == 0\n",
    "    mask_1 = X_test['sex'] == 1\n",
    "\n",
    "    precision_0 = recall_score(y_true[mask_0], y_pred[mask_0], pos_label=True)\n",
    "    precision_1 = recall_score(y_true[mask_1], y_pred[mask_1], pos_label=True)\n",
    "    \n",
    "    rate_difference = abs(precision_0-precision_1)\n",
    "    \n",
    "    if rate_difference <= 0.05:\n",
    "        success = True\n",
    "    else:\n",
    "        success = False\n",
    "    \n",
    "    return success, rate_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.04513888888888884)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = pd.read_csv(os.path.join('data', 'data_model_1.csv'))\n",
    "X_test1 = model_1.copy().drop(columns=['target', 'prediction'])\n",
    "y_test1 = model_1.target\n",
    "y_pred1 = model_1.prediction\n",
    "\n",
    "verify_retrieve_rates(X_test1, y_test1, y_pred1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.04513888888888884)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = pd.read_csv(os.path.join('data', 'data_model_2.csv'))\n",
    "\n",
    "X_test2 = model_2.copy().drop(columns=['target', 'prediction'])\n",
    "y_test2 = model_2.target\n",
    "y_pred2 = model_2.prediction\n",
    "\n",
    "verify_retrieve_rates(X_test2, y_test2, y_pred2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8c29ef35a9d73ebd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Verify your function is working on a couple of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d445e07c99ff6fff",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_1 = pd.read_csv(os.path.join('data', 'data_model_1.csv'))\n",
    "\n",
    "X_test = model_1.copy().drop(columns=['target', 'prediction'])\n",
    "y_test = model_1.target\n",
    "y_pred = model_1.prediction\n",
    "\n",
    "success, rate_diff = verify_retrieve_rates(X_test, y_test, y_pred) \n",
    "assert success is False\n",
    "assert math.isclose(rate_diff, 0.20138888888888884)\n",
    "\n",
    "model_2 = pd.read_csv(os.path.join('data', 'data_model_2.csv'))\n",
    "\n",
    "X_test = model_2.copy().drop(columns=['target', 'prediction'])\n",
    "y_test = model_2.target\n",
    "y_pred = model_2.prediction\n",
    "\n",
    "success, rate_diff = verify_retrieve_rates(X_test, y_test, y_pred) \n",
    "assert success is True\n",
    "assert math.isclose(rate_diff, 0.04513888888888884)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f60c10e28e9ad450",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you passed the asserts, you've defused this task. Move forward to the next one \n",
    "\n",
    "<img src=\"media/client-specs.png\" width=400 />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Q2) Prepare the model to be served\n",
    "\n",
    "\n",
    "Now use the model that you built for Q1 and build a predict function around it that will parse the request and return the respective prediction. Split your code into initialization and prediction code as you've learned. Additionally, instead of returning 0 or 1, return True or False. Do not worry about potential bad inputs at this point, we'll get to it later on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-41c50b60ab6b94be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialization code\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "def predict(request):\n",
    "    \"\"\"\n",
    "    Produce prediction for request.\n",
    "    \n",
    "    Inputs:\n",
    "        request: dictionary with format described below\n",
    "        \n",
    "        ```\n",
    "        {\n",
    "            \"observation_id\": <id-as-a-string>,\n",
    "            \"data\": {\n",
    "                \"age\": <value>,\n",
    "                \"sex\": <value>,\n",
    "                \"cp\": <value>,\n",
    "                \"trestbps\": <value>,\n",
    "                \"fbs\": <value>,\n",
    "                \"restecg\": <value>,\n",
    "                \"oldpeak\": <value>,\n",
    "                \"ca\": <value>,\n",
    "                \"thal\": <value>\n",
    "            }\n",
    "        }\n",
    "        ```\n",
    "    \n",
    "    Returns:\n",
    "        response: A dictionary echoing the request and its data with the addition of the prediction and probability \n",
    "            ```\n",
    "            {\n",
    "                \"observation_id\": <id-of-request>,\n",
    "                \"age\": <value-of-request>,\n",
    "                \"sex\": <value-of-request>,\n",
    "                \"cp\": <value-of-request>,\n",
    "                \"trestbps\": <value-of-request>,\n",
    "                \"fbs\": <value-of-request>,\n",
    "                \"restecg\": <value-of-request>,\n",
    "                \"oldpeak\": <value-of-request>,\n",
    "                \"ca\": <value-of-request>,\n",
    "                \"thal\": <value-of-request>,\n",
    "                \"prediction\": <True|False>,\n",
    "                \"probability\": <probability generated by model>\n",
    "            }\n",
    "            ```\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    with open(os.path.join('tmp', 'columns.json')) as fh:\n",
    "        columns = json.load(fh)\n",
    "\n",
    "\n",
    "    with open(os.path.join('tmp', 'pipeline.pickle'), 'rb') as fh:\n",
    "        pipeline = joblib.load(fh)\n",
    "\n",
    "\n",
    "    with open(os.path.join('tmp', 'dtypes.pickle'), 'rb') as fh:\n",
    "        dtypes = pickle.load(fh)\n",
    "    \n",
    "    obs_dict = request\n",
    "    _id = obs_dict['observation_id']\n",
    "    observation = obs_dict['data']\n",
    "    obs = pd.DataFrame([observation], columns=columns).astype(dtypes)\n",
    "    proba = pipeline.predict_proba(obs)[0, 1]\n",
    "    prediction = pipeline.predict(obs)[0]\n",
    "    response = {\n",
    "                \"observation_id\": _id,\n",
    "                \"age\": obs.age[0],\n",
    "                \"sex\": obs.sex[0],\n",
    "                \"cp\": obs.cp[0],\n",
    "                \"trestbps\": obs.trestbps[0],\n",
    "                \"fbs\": obs.fbs[0],\n",
    "                \"restecg\": obs.restecg[0],\n",
    "                \"oldpeak\": obs.oldpeak[0],\n",
    "                \"ca\": obs.ca[0],\n",
    "                \"thal\": obs.thal[0],\n",
    "                \"prediction\": bool(prediction),\n",
    "                \"probability\": proba\n",
    "                }\n",
    "    \n",
    "        \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-053d4ccfe2e0d5cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Test your function on the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-50f083e22995d498",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "request = {\n",
    "    \"observation_id\": \"1\",\n",
    "    \"data\": \n",
    "        {\n",
    "            \"age\": 23, \n",
    "            \"sex\": 1, \n",
    "            \"cp\": 3, \n",
    "            \"trestbps\": 120, \n",
    "            \"fbs\": 1, \n",
    "            \"restecg\": 1, \n",
    "            \"oldpeak\": 0, \n",
    "            \"ca\": 0, \n",
    "            \"thal\": 1\n",
    "        }\n",
    "}\n",
    "\n",
    "response = predict(request)\n",
    "assert sorted(response.keys()) == \\\n",
    "    sorted([\"observation_id\", \"age\", \"sex\", \"cp\", \"trestbps\", \"fbs\", \"restecg\", \n",
    "            \"oldpeak\", \"ca\", \"thal\", \"prediction\", \"probability\"])\n",
    "\n",
    "assert response[\"observation_id\"] == \"1\"\n",
    "assert response[\"age\"] == 23\n",
    "assert response[\"restecg\"] == 1\n",
    "assert response[\"prediction\"] in [True, False]\n",
    "\n",
    "probability_1 = response[\"probability\"] \n",
    "\n",
    "\n",
    "request = {\n",
    "    \"observation_id\": \"2\",\n",
    "    \"data\": \n",
    "        {\n",
    "            \"age\": 44, \n",
    "            \"sex\": 0, \n",
    "            \"cp\": 2, \n",
    "            \"trestbps\": 170, \n",
    "            \"fbs\": 1, \n",
    "            \"restecg\": 1, \n",
    "            \"oldpeak\": 1, \n",
    "            \"ca\": 0, \n",
    "            \"thal\": 2\n",
    "        }\n",
    "}\n",
    "\n",
    "response = predict(request)\n",
    "assert sorted(response.keys()) == \\\n",
    "    sorted([\"observation_id\", \"age\", \"sex\", \"cp\", \"trestbps\", \"fbs\", \"restecg\", \n",
    "            \"oldpeak\", \"ca\", \"thal\", \"prediction\", \"probability\"])\n",
    "\n",
    "assert response[\"observation_id\"] == \"2\"\n",
    "assert response[\"fbs\"] == 1\n",
    "assert response[\"restecg\"] == 1\n",
    "assert response[\"prediction\"] in [True, False]\n",
    "\n",
    "probability_2 = response[\"probability\"] \n",
    "\n",
    "assert probability_1 != probability_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-405026099770218f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "Hurray! It passed the tests. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Q3) Make sure your input is correct\n",
    "\n",
    "Now let's be a bit more thorough\n",
    "\n",
    "Protect your function against unexpected inputs. Create a function similar to the one before, but \n",
    "this time, return a different response. If everything is well with your request return an answer like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"observation_id\": \"id1234\",\n",
    "    \"prediction\": True,\n",
    "    \"probability\": 0.4\n",
    "}\n",
    "```\n",
    "\n",
    "However, if there is a problem with the initial data, whether it's fields missing or invalid values, return a different response:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"observation_id\": \"id1234\",\n",
    "    \"error\": \"Some error occured\",\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "#### Hints \n",
    "\n",
    "- Hint 1: If the `observation_id` is not present, set it to None\n",
    "- Hint 2: Check out the tests to see what we expect from the error cases and error messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba9eb7b46c393f65",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observation_id': '1', 'error': {'bloodpressure'}}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialization code\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "def attempt_predict(request):\n",
    "    \"\"\"\n",
    "    Produce prediction for request.\n",
    "    \n",
    "    Inputs:\n",
    "        request: dictionary with format described below\n",
    "        \n",
    "        ```\n",
    "        {\n",
    "            \"observation_id\": <id-as-a-string>,\n",
    "            \"data\": {\n",
    "                \"age\": <value>,\n",
    "                \"sex\": <value>,\n",
    "                \"cp\": <value>,\n",
    "                \"trestbps\": <value>,\n",
    "                \"fbs\": <value>,\n",
    "                \"restecg\": <value>,\n",
    "                \"oldpeak\": <value>,\n",
    "                \"ca\": <value>,\n",
    "                \"thal\": <value>\n",
    "            }\n",
    "        }\n",
    "        ```\n",
    "     \n",
    "    Returns: A dictionary with predictions or an error, the two potential values:\n",
    "                ```\n",
    "                {\n",
    "                    \"observation_id\": <id-of-request>,\n",
    "                    \"prediction\": <True|False>,\n",
    "                    \"probability\": <probability generated by model>\n",
    "                }\n",
    "                ```\n",
    "                or \n",
    "                ```\n",
    "                {\n",
    "                    \"observation_id\": <id-of-request>,\n",
    "                    \"error\": \"some error message\"\n",
    "                }\n",
    "                ```\n",
    "                if success is False, return an error string\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    with open(os.path.join('tmp', 'columns.json')) as fh:\n",
    "        columns = json.load(fh)\n",
    "\n",
    "\n",
    "    with open(os.path.join('tmp', 'pipeline.pickle'), 'rb') as fh:\n",
    "        pipeline = joblib.load(fh)\n",
    "\n",
    "\n",
    "    with open(os.path.join('tmp', 'dtypes.pickle'), 'rb') as fh:\n",
    "        dtypes = pickle.load(fh)\n",
    "    \n",
    "    \n",
    "    obs_dict = request\n",
    "        \n",
    "    #data validation\n",
    "    error_validation = 0\n",
    "\n",
    "    #check if the resquest has id and data\n",
    "    if \"observation_id\" not in request:\n",
    "        error_validation = 1\n",
    "       \n",
    "        return {'observation_id': None,\n",
    "                \"error\": \"observation_id\"\n",
    "               }\n",
    "    else:\n",
    "        _id = obs_dict['observation_id']\n",
    "        \n",
    "\n",
    "    if \"data\" not in request:\n",
    "        error_validation = 1\n",
    "        \n",
    "        return {'observation_id': _id,\n",
    "                \"error\": \"data\"\n",
    "               }\n",
    "    else:\n",
    "        \n",
    "        #columns's check\n",
    "        valid_columns = {'age', 'sex', 'cp', 'trestbps', 'fbs', 'restecg', 'oldpeak', 'ca', 'thal'}\n",
    "\n",
    "        keys = set(obs_dict['data'].keys())\n",
    "\n",
    "        if len(valid_columns - keys) > 0: \n",
    "            missing = valid_columns - keys\n",
    "            error_validation = 1\n",
    "            \n",
    "            return {'observation_id': _id,\n",
    "                    \"error\": missing\n",
    "                   }\n",
    "\n",
    "        if len(keys - valid_columns) > 0: \n",
    "            extra = keys - valid_columns\n",
    "            error_validation = 1\n",
    "            \n",
    "            return {'observation_id': _id,\n",
    "                    \"error\": extra\n",
    "                   }\n",
    "\n",
    "    #check correct values \n",
    "    observation = obs_dict['data']\n",
    "    valid_category_map = {\n",
    "                            \"sex\": [0,1],\n",
    "                            \"cp\": [0,1,2,3],\n",
    "                            \"fbs\": [0,1],\n",
    "                            \"restecg\": [0,1,2],\n",
    "                            \"ca\": [0,1,2,3,4],\n",
    "                            \"thal\": [0,1,2,3]\n",
    "                         }\n",
    "    \n",
    "    for key, valid_categories in valid_category_map.items():\n",
    "        if key in observation:\n",
    "            value = observation[key]\n",
    "            if value not in valid_categories:\n",
    "                error = value\n",
    "                return {'observation_id': _id,\n",
    "                        \"error\": key + ' ' + str(value)\n",
    "                       }\n",
    "     \n",
    "    if observation.get(\"age\") < 0 or observation.get(\"age\") > 100:\n",
    "        return {'observation_id': _id,\n",
    "                \"error\": 'age' + ' ' + str(observation.get(\"age\"))\n",
    "                }\n",
    "    \n",
    "    if observation.get(\"trestbps\") <= 10 or observation.get(\"trestbps\") >= 500:\n",
    "        return {'observation_id': _id,\n",
    "                \"error\": 'trestbps' + ' ' + str(observation.get(\"trestbps\"))\n",
    "                }\n",
    "    \n",
    "    if observation.get(\"oldpeak\") >= 12:\n",
    "        return {'observation_id': _id,\n",
    "                \"error\": 'oldpeak' + ' ' + str(observation.get(\"oldpeak\"))\n",
    "                }\n",
    "                   \n",
    "    if error_validation == 0:\n",
    "        \n",
    "        obs = pd.DataFrame([observation], columns=columns).astype(dtypes)\n",
    "        proba = pipeline.predict_proba(obs)[0, 1]\n",
    "        prediction = pipeline.predict(obs)[0]\n",
    "        response = {\n",
    "                    'observation_id': _id,\n",
    "                    \"prediction\": bool(prediction),\n",
    "                    \"probability\": proba\n",
    "                    }\n",
    "\n",
    "\n",
    "    return response\n",
    "\n",
    "attempt_predict(bad_request_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58    14\n",
      "54    12\n",
      "57    10\n",
      "52     9\n",
      "59     9\n",
      "60     8\n",
      "44     8\n",
      "51     8\n",
      "53     8\n",
      "65     8\n",
      "63     8\n",
      "41     7\n",
      "43     6\n",
      "56     6\n",
      "61     6\n",
      "62     6\n",
      "64     6\n",
      "66     6\n",
      "67     6\n",
      "42     5\n",
      "45     5\n",
      "47     5\n",
      "49     5\n",
      "55     5\n",
      "50     4\n",
      "48     4\n",
      "35     4\n",
      "70     4\n",
      "39     4\n",
      "68     3\n",
      "46     3\n",
      "37     2\n",
      "38     2\n",
      "34     1\n",
      "77     1\n",
      "74     1\n",
      "69     1\n",
      "71     1\n",
      "29     1\n",
      "Name: age, dtype: int64\n",
      "1    140\n",
      "0     72\n",
      "Name: sex, dtype: int64\n",
      "0    96\n",
      "2    67\n",
      "1    33\n",
      "3    16\n",
      "Name: cp, dtype: int64\n",
      "130    31\n",
      "120    31\n",
      "140    17\n",
      "110    15\n",
      "112     9\n",
      "138     9\n",
      "150     9\n",
      "160     7\n",
      "128     7\n",
      "125     6\n",
      "108     6\n",
      "132     5\n",
      "118     5\n",
      "124     5\n",
      "134     4\n",
      "135     4\n",
      "152     4\n",
      "145     3\n",
      "136     3\n",
      "180     3\n",
      "100     3\n",
      "126     2\n",
      "115     2\n",
      "122     2\n",
      "94      2\n",
      "142     2\n",
      "146     2\n",
      "148     2\n",
      "144     1\n",
      "123     1\n",
      "155     1\n",
      "156     1\n",
      "164     1\n",
      "114     1\n",
      "170     1\n",
      "172     1\n",
      "174     1\n",
      "101     1\n",
      "178     1\n",
      "192     1\n",
      "Name: trestbps, dtype: int64\n",
      "0    185\n",
      "1     27\n",
      "Name: fbs, dtype: int64\n",
      "1    109\n",
      "0    100\n",
      "2      3\n",
      "Name: restecg, dtype: int64\n",
      "0.0    67\n",
      "1.2    16\n",
      "0.8    11\n",
      "1.0    11\n",
      "0.6    10\n",
      "1.6     9\n",
      "1.4     7\n",
      "1.8     7\n",
      "0.2     7\n",
      "0.1     6\n",
      "0.4     6\n",
      "2.0     5\n",
      "1.5     5\n",
      "2.6     4\n",
      "3.0     4\n",
      "2.8     4\n",
      "0.5     4\n",
      "1.9     3\n",
      "2.2     3\n",
      "0.9     3\n",
      "2.3     2\n",
      "4.0     2\n",
      "2.5     2\n",
      "2.4     2\n",
      "3.4     2\n",
      "3.5     1\n",
      "2.9     1\n",
      "3.2     1\n",
      "3.6     1\n",
      "5.6     1\n",
      "3.1     1\n",
      "4.4     1\n",
      "1.1     1\n",
      "0.3     1\n",
      "3.8     1\n",
      "Name: oldpeak, dtype: int64\n",
      "0    129\n",
      "1     47\n",
      "2     20\n",
      "3     15\n",
      "4      1\n",
      "Name: ca, dtype: int64\n",
      "2    118\n",
      "3     82\n",
      "1     11\n",
      "0      1\n",
      "Name: thal, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in list_features:\n",
    "    print(df_train[i].value_counts(dropna=False))\n",
    "\n",
    "# valid_category_map = {\n",
    "#                             \"sex\": [0,1],\n",
    "#                             \"cp\": [0,1,2,3],\n",
    "#                             \"fbs\": [0,1],\n",
    "#                             \"restecg\": [0,1,2],\n",
    "#                             \"ca\": [0,1,2,3,4],\n",
    "#                             \"thal\": [0,1,2,3]\n",
    "#                          }\n",
    "\n",
    "# bad_request_5 = deepcopy(base_request)\n",
    "# bad_request_5['data']['sex'] = 5\n",
    "\n",
    "# observation=bad_request_5['data']\n",
    "\n",
    "# for key, valid_categories in valid_category_map.items():\n",
    "#     if key in observation:\n",
    "#         value = observation[key]\n",
    "#         if value not in valid_categories:\n",
    "#             error = value\n",
    "#             print({'observation_id': 1,\"error\": value})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-159253e9dbf17db6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the tests below to validate your function is protected against some simple cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5fdd682e3b4da185",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "# Test with good payload\n",
    "################################################\n",
    "\n",
    "base_request = {\n",
    "    \"observation_id\": \"1\",\n",
    "    \"data\": \n",
    "        {\n",
    "            \"age\": 23, \n",
    "            \"sex\": 1, \n",
    "            \"cp\": 3, \n",
    "            \"trestbps\": 120, \n",
    "            \"fbs\": 1, \n",
    "            \"restecg\": 1, \n",
    "            \"oldpeak\": 0.0, \n",
    "            \"ca\": 0, \n",
    "            \"thal\": 1\n",
    "        }\n",
    "}\n",
    "\n",
    "response = attempt_predict(base_request)\n",
    "assert 'prediction' in response, response\n",
    "assert 'probability' in response, response\n",
    "assert 'observation_id' in response, response\n",
    "\n",
    "assert response[\"observation_id\"] == \"1\", response[\"observation_id\"]\n",
    "assert response[\"prediction\"] in [True, False], response[\"prediction\"] \n",
    "assert response[\"probability\"] <= 1.0, response[\"probability\"] \n",
    "assert response[\"probability\"] >= 0.0, response[\"probability\"] \n",
    "\n",
    "\n",
    "################################################\n",
    "# Test missing `observation_id` produces an error\n",
    "################################################\n",
    "\n",
    "bad_request_1 = deepcopy(base_request)\n",
    "bad_request_1['random_field'] = bad_request_1.pop('observation_id')\n",
    "\n",
    "response = attempt_predict(bad_request_1)\n",
    "assert 'error' in response, response\n",
    "assert 'observation_id' in response['error'] \n",
    "\n",
    "\n",
    "################################################\n",
    "# Test missing `data` produces an error\n",
    "################################################\n",
    "\n",
    "bad_request_2 = deepcopy(base_request)\n",
    "bad_request_2['data_field_name'] = bad_request_2.pop('data')\n",
    "\n",
    "response = attempt_predict(bad_request_2)\n",
    "assert 'error' in response, response\n",
    "assert 'data' in response['error'] \n",
    "\n",
    "\n",
    "################################################\n",
    "# Test missing columns produce an error\n",
    "################################################\n",
    "\n",
    "bad_request_3 = deepcopy(base_request)\n",
    "bad_request_3['data'].pop('age')\n",
    "\n",
    "response = attempt_predict(bad_request_3)\n",
    "assert 'error' in response, response\n",
    "assert 'age' in response['error'], response['error']\n",
    "\n",
    "\n",
    "################################################\n",
    "# Test extra columns produce an error\n",
    "################################################\n",
    "\n",
    "bad_request_4 = deepcopy(base_request)\n",
    "bad_request_4['data']['bloodpressure'] = 2\n",
    "\n",
    "response = attempt_predict(bad_request_4)\n",
    "assert 'error' in response, response\n",
    "assert 'bloodpressure' in response['error'], response['error']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f7c6084210b7712f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run a couple more tests to make sure your server is bulletproof:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-001653d2c8007a1a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "####################################################\n",
    "# Test invalid values for categorical features - sex\n",
    "####################################################\n",
    "\n",
    "bad_request_5 = deepcopy(base_request)\n",
    "bad_request_5['data']['sex'] = 3\n",
    "\n",
    "response = attempt_predict(bad_request_5)\n",
    "assert 'error' in response, response\n",
    "assert 'sex' in response['error'], response['error']\n",
    "assert '3' in response['error'], response['error']\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "# Test invalid values for categorical features - number of vessels coloured\n",
    "###########################################################################\n",
    "\n",
    "bad_request_6 = deepcopy(base_request)\n",
    "bad_request_6['data']['ca'] = 'Hello world'\n",
    "\n",
    "response = attempt_predict(bad_request_6)\n",
    "assert 'error' in response, response\n",
    "assert 'ca' in response['error'], response['error']\n",
    "assert 'Hello world' in response['error'], response['error']\n",
    "\n",
    "\n",
    "####################################################\n",
    "# Test invalid values for numerical features - age\n",
    "####################################################\n",
    "\n",
    "bad_request_7 = deepcopy(base_request)\n",
    "bad_request_7['data']['age'] = -12\n",
    "\n",
    "response = attempt_predict(bad_request_7)\n",
    "assert 'error' in response, response\n",
    "assert 'age' in response['error'], response['error']\n",
    "assert '-12' in response['error'], response['error']\n",
    "\n",
    "bad_request_8 = deepcopy(base_request)\n",
    "bad_request_8['data']['age'] = 1200\n",
    "\n",
    "response = attempt_predict(bad_request_8)\n",
    "assert 'error' in response, response\n",
    "assert 'age' in response['error'], response['error']\n",
    "assert '1200' in response['error'], response['error']\n",
    "\n",
    "\n",
    "####################################################\n",
    "# Test invalid values for numerical features - trestbps\n",
    "####################################################\n",
    "\n",
    "bad_request_9 = deepcopy(base_request)\n",
    "bad_request_9['data']['trestbps'] = 10\n",
    "\n",
    "response = attempt_predict(bad_request_9)\n",
    "assert 'error' in response, response\n",
    "assert 'trestbps' in response['error'], response['error']\n",
    "assert '10' in response['error'], response['error']\n",
    "\n",
    "bad_request_10 = deepcopy(base_request)\n",
    "bad_request_10['data']['trestbps'] = 500\n",
    "\n",
    "response = attempt_predict(bad_request_10)\n",
    "assert 'error' in response, response\n",
    "assert 'trestbps' in response['error'], response['error']\n",
    "assert '500' in response['error'], response['error']\n",
    "\n",
    "\n",
    "####################################################\n",
    "# Test invalid values for numerical features - oldpeak\n",
    "####################################################\n",
    "\n",
    "bad_request_11 = deepcopy(base_request)\n",
    "bad_request_11['data']['oldpeak'] = 12\n",
    "\n",
    "response = attempt_predict(bad_request_11)\n",
    "assert 'error' in response, response\n",
    "assert 'oldpeak' in response['error'], response['error']\n",
    "assert '12' in response['error'], response['error']\n",
    "\n",
    "bad_request_12 = deepcopy(base_request)\n",
    "bad_request_12['data']['oldpeak'] = 40.312\n",
    "\n",
    "response = attempt_predict(bad_request_12)\n",
    "assert 'error' in response, response\n",
    "assert 'oldpeak' in response['error'], response['error']\n",
    "assert '40.312' in response['error'], response['error']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27c74c3d31a3055f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "Ufff. That was tough. But now your app is a bit safer to deploy! At least from all the cases we could think of.\n",
    "\n",
    "<img src=\"media/code-passes-tests.png\" width=500 />\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Q4) Put everything together\n",
    "\n",
    "Finally, build a server with your model and a predict endpoint protected from all the cases before. Deploy it and set \n",
    "the name of your app below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fd9977536ad6270d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Assign the variable APP_NAME to the name of your heroku app\n",
    "# APP_NAME = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-07135d75c857276c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "Test that your server is bulletproof:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ac0c1a590d9aba53",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test locally\n",
    "# url = f\"http://localhost:5000/predict\"\n",
    "\n",
    "\n",
    "# Testing the predict/update endpoint\n",
    "url = \"https://{}.herokuapp.com/predict\".format(APP_NAME)\n",
    "\n",
    "\n",
    "################################################\n",
    "# Test with good payload\n",
    "################################################\n",
    "\n",
    "payload = {\n",
    "    \"observation_id\": str(uuid4()),\n",
    "    \"data\": \n",
    "        {\n",
    "            \"age\": 23, \n",
    "            \"sex\": 1, \n",
    "            \"cp\": 3, \n",
    "            \"trestbps\": 120, \n",
    "            \"fbs\": 1, \n",
    "            \"restecg\": 1, \n",
    "            \"oldpeak\": 0.0, \n",
    "            \"ca\": 0, \n",
    "            \"thal\": 1\n",
    "        }\n",
    "}\n",
    "\n",
    "r = requests.post(url, json=payload)\n",
    "assert isinstance(r, requests.Response)\n",
    "assert r.ok\n",
    "\n",
    "response = r.json()\n",
    "\n",
    "assert 'prediction' in response, response\n",
    "assert 'probability' in response, response\n",
    "\n",
    "assert response[\"prediction\"] in [True, False]\n",
    "\n",
    "assert isinstance(response[\"probability\"], float)\n",
    "assert 0 <= response[\"probability\"] <= 1\n",
    "\n",
    "\n",
    "################################################\n",
    "# Test missing `observation_id` produces an error\n",
    "################################################\n",
    "\n",
    "bad_payload_1 = deepcopy(payload)\n",
    "bad_payload_1['random_field'] = bad_payload_1.pop('observation_id')\n",
    "\n",
    "r = requests.post(url, json=bad_payload_1)\n",
    "assert isinstance(r, requests.Response)\n",
    "assert r.ok\n",
    "\n",
    "response = r.json()\n",
    "\n",
    "assert 'error' in response, response\n",
    "assert 'observation_id' in response['error'], response['error']\n",
    "\n",
    "\n",
    "################################################\n",
    "# Test missing `data` produces an error\n",
    "################################################\n",
    "\n",
    "bad_payload_2 = deepcopy(payload)\n",
    "bad_payload_2['observation_id'] = str(uuid4())\n",
    "bad_payload_2['random_field'] = bad_payload_2.pop('data')\n",
    "\n",
    "r = requests.post(url, json=bad_payload_2)\n",
    "assert isinstance(r, requests.Response)\n",
    "assert r.ok\n",
    "\n",
    "response = r.json()\n",
    "\n",
    "assert 'error' in response, response\n",
    "assert 'data' in response['error'], response['error']\n",
    "\n",
    "\n",
    "################################################\n",
    "# Test missing columns produce an error\n",
    "################################################\n",
    "\n",
    "bad_payload_3 = deepcopy(payload)\n",
    "bad_payload_3['observation_id'] = str(uuid4())\n",
    "bad_payload_3['data'].pop('age')\n",
    "\n",
    "r = requests.post(url, json=bad_payload_3)\n",
    "assert isinstance(r, requests.Response)\n",
    "assert r.ok\n",
    "\n",
    "response = r.json()\n",
    "\n",
    "assert 'error' in response, response\n",
    "assert 'age' in response['error'], response['error']\n",
    "\n",
    "\n",
    "################################################\n",
    "# Test extra columns produce an error\n",
    "################################################\n",
    "\n",
    "bad_payload_4 = deepcopy(payload)\n",
    "bad_payload_4['observation_id'] = str(uuid4())\n",
    "bad_payload_4['data']['bloodpressure'] = 100\n",
    "\n",
    "r = requests.post(url, json=bad_payload_4)\n",
    "assert isinstance(r, requests.Response)\n",
    "assert r.ok\n",
    "\n",
    "response = r.json()\n",
    "\n",
    "assert 'error' in response, response\n",
    "assert 'bloodpressure' in response['error'], response['error']\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "# Test invalid values for categorical features - number of vessels coloured\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "bad_payload_5 = deepcopy(payload)\n",
    "bad_payload_5['observation_id'] = str(uuid4())\n",
    "bad_payload_5['data']['ca'] = 'Hello world'\n",
    "\n",
    "r = requests.post(url, json=bad_payload_5)\n",
    "assert isinstance(r, requests.Response)\n",
    "assert r.ok\n",
    "\n",
    "response = r.json()\n",
    "\n",
    "assert 'error' in response, response\n",
    "assert 'ca' in response['error'], response['error']\n",
    "assert 'Hello world' in response['error'], response['error']\n",
    "\n",
    "\n",
    "####################################################\n",
    "# Test invalid values for numerical features - age\n",
    "####################################################\n",
    "\n",
    "bad_payload_6 = deepcopy(payload)\n",
    "bad_payload_6['observation_id'] = str(uuid4())\n",
    "bad_payload_6['data']['age'] = -12\n",
    "\n",
    "r = requests.post(url, json=bad_payload_6)\n",
    "assert isinstance(r, requests.Response)\n",
    "assert r.ok\n",
    "\n",
    "response = r.json()\n",
    "\n",
    "assert 'error' in response, response\n",
    "assert 'age' in response['error'], response['error']\n",
    "assert '-12' in response['error'], response['error']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8088ad24d8aadbc8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "And... you're done. You have successfully built a model, assessed if it passed the client requirements, built an app and protected it from crappy input. \n",
    "\n",
    "It's time for a well deserved rest, so go ahead and go be a couch potato.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"media/lays.png\" width=400 />\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
