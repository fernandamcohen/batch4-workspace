{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## HACKATHON 1\n",
    "########################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingClassifier,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 419487 entries, 0 to 419486\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   ID                     419487 non-null  int64  \n",
      " 1   DATE_DEPARTURE_UTC     419487 non-null  object \n",
      " 2   DATE_ARRIVAL_UTC       419487 non-null  object \n",
      " 3   DATE_DEPARTURE_LCL     419487 non-null  object \n",
      " 4   DATE_ARRIVAL_LCL       419487 non-null  object \n",
      " 5   ORIGIN                 419487 non-null  object \n",
      " 6   ORIGIN_AIRPORT_ID      419487 non-null  int64  \n",
      " 7   DEST                   419487 non-null  object \n",
      " 8   DEST_AIRPORT_ID        419487 non-null  int64  \n",
      " 9   TAIL_NUM               419487 non-null  object \n",
      " 10  OP_CARRIER             419487 non-null  object \n",
      " 11  OP_CARRIER_AIRLINE_ID  419487 non-null  int64  \n",
      " 12  OP_CARRIER_FL_NUM      419487 non-null  int64  \n",
      " 13  DISTANCE               401869 non-null  float64\n",
      " 14  CANCELLED              419487 non-null  int64  \n",
      " 15  DEP_DEL15              272667 non-null  float64\n",
      " 16  ARR_DEL15              419487 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(8)\n",
      "memory usage: 54.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train.info()\n",
    "#test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                            0\n",
      "DATE_DEPARTURE_UTC            0\n",
      "DATE_ARRIVAL_UTC              0\n",
      "DATE_DEPARTURE_LCL            0\n",
      "DATE_ARRIVAL_LCL              0\n",
      "ORIGIN                        0\n",
      "ORIGIN_AIRPORT_ID             0\n",
      "DEST                          0\n",
      "DEST_AIRPORT_ID               0\n",
      "TAIL_NUM                      0\n",
      "OP_CARRIER                    0\n",
      "OP_CARRIER_AIRLINE_ID         0\n",
      "OP_CARRIER_FL_NUM             0\n",
      "DISTANCE                  17618\n",
      "CANCELLED                     0\n",
      "DEP_DEL15                146820\n",
      "ARR_DEL15                     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                       419487\n",
       "DATE_DEPARTURE_UTC        29661\n",
       "DATE_ARRIVAL_UTC          30137\n",
       "DATE_DEPARTURE_LCL        26687\n",
       "DATE_ARRIVAL_LCL          28477\n",
       "ORIGIN                      351\n",
       "ORIGIN_AIRPORT_ID           351\n",
       "DEST                        350\n",
       "DEST_AIRPORT_ID             350\n",
       "TAIL_NUM                   5376\n",
       "OP_CARRIER                   17\n",
       "OP_CARRIER_AIRLINE_ID        17\n",
       "OP_CARRIER_FL_NUM          6715\n",
       "DISTANCE                   1468\n",
       "CANCELLED                     1\n",
       "DEP_DEL15                     2\n",
       "ARR_DEL15                     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analizing the variables\n",
    "train.describe()\n",
    "\n",
    "#quantity of missing per feature - DISTANCE, DEP_DEL15\n",
    "print(train.isnull().sum())\n",
    "\n",
    "#categories per feature\n",
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING - Part 1\n",
    "\n",
    "    #convert timestamp variables\n",
    "    #create new features:\n",
    "        #flag of holiday\n",
    "        #flag day befor a holiday\n",
    "        #day of the week\n",
    "        #period of the day - morning/afternoon/night\n",
    "        #flight duration = DATE_ARRIVAL_UTC - DATE_DEPARTURE_UTC\n",
    "        #stardarized flight duration\n",
    "    #transform OP_CARRIER in a categorical variable\n",
    "    #drop of the analysis: CANCELLED, DATE_DEPARTURE_LCL, DATE_ARRIVAL_LCL, TAIL_NUM\n",
    "    #deal with missing values: categorize DEP_DEL15 using missing as a category\n",
    "\n",
    "def feature_engineering(_df):\n",
    "    mod_df = _df.copy()\n",
    "    \n",
    "    mod_df.drop(['ORIGIN_AIRPORT_ID', 'DEST_AIRPORT_ID', 'CANCELLED','TAIL_NUM'], inplace = True, axis = 1)\n",
    "    \n",
    "    #convert timestamp variables\n",
    "    mod_df['DATE_ARRIVAL_UTC_ts'] = pd.to_datetime(mod_df['DATE_ARRIVAL_UTC'])\n",
    "    mod_df['DATE_DEPARTURE_UTC_ts'] = pd.to_datetime(mod_df['DATE_DEPARTURE_UTC'])\n",
    "    mod_df['DATE_ARRIVAL_LCL_ts'] = pd.to_datetime(mod_df['DATE_ARRIVAL_LCL'])\n",
    "    mod_df['DATE_DEPARTURE_LCL_ts'] = pd.to_datetime(mod_df['DATE_DEPARTURE_LCL'])\n",
    "    \n",
    "    #weekday\n",
    "    mod_df['WeekDay_DEPARTURE_UTC'] = pd.to_datetime(mod_df['DATE_DEPARTURE_UTC_ts']).dt.weekday\n",
    "    mod_df['WeekDay_ARRIVAL_UTC'] = pd.to_datetime(mod_df['DATE_ARRIVAL_UTC_ts']).dt.weekday\n",
    "    \n",
    "    #transform OP_CARRIER in a categorical variable\n",
    "    mod_df['OP_CARRIER'] = mod_df['OP_CARRIER'].astype('category')\n",
    "    \n",
    "    #deal with missing values\n",
    "    mod_df['DEP_DEL15_cat'] = mod_df['DEP_DEL15'].fillna(2).astype('category').map({1: 'delayed', 0: 'not delayed', 2: 'unknown'})\n",
    "    mod_df = mod_df.join(pd.get_dummies(mod_df['DEP_DEL15_cat']))\n",
    "    \n",
    "    #duration of the flight\n",
    "    mod_df['Duration_UTC'] = (mod_df['DATE_ARRIVAL_UTC_ts'] - mod_df['DATE_DEPARTURE_UTC_ts']).dt.seconds/60\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    mod_df['Duration_UTC_Standard'] = scaler.fit_transform(pd.DataFrame(mod_df['Duration_UTC']))\n",
    "\n",
    "    #Federal holidays\n",
    "    mod_df['NewYear_Flag'] = mod_df['DATE_DEPARTURE_UTC'].str.contains('01-01').map({True: 1, False: 0})\n",
    "    mod_df['MartinLutherKingDay_Flag'] = mod_df['DATE_DEPARTURE_UTC'].str.contains('01-20').map({True: 1, False: 0})\n",
    "    \n",
    "    return mod_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING - Part 2\n",
    "    #deal with missing values: use median to DISTANCE\n",
    "class ValueImputer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.fills = X.median(axis=0).squeeze()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(X).fillna(self.fills)\n",
    "\n",
    "#FEATURE ENGINEERING - Part 3\n",
    "    #stardarized DISTANCE\n",
    "def Standard_Distance(_df, feature):\n",
    "    mod_df = _df.copy()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    mod_df['Distance_Standard'] = scaler.fit_transform(pd.DataFrame(mod_df[feature]))\n",
    "    \n",
    "    return mod_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(293640, 29)\n",
      "(293640,)\n",
      "(125847, 29)\n",
      "(125847,)\n"
     ]
    }
   ],
   "source": [
    "## APPLAYING THE PREVIOUS STEPS\n",
    "\n",
    "train_target = train['ARR_DEL15']\n",
    "train_adj = feature_engineering(train)\n",
    "\n",
    "imputer = ValueImputer()\n",
    "train_adj['DISTANCE_noNaN'] = imputer.fit_transform(train_adj['DISTANCE'])\n",
    "train_adj = Standard_Distance(train_adj, 'DISTANCE_noNaN')\n",
    "\n",
    "#Sorting to do split into train and test set\n",
    "train_adj = train_adj.sort_values(by=\"DATE_DEPARTURE_UTC_ts\")\n",
    "\n",
    "## SPLIT TRAIN SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_adj, train_target, test_size=0.3, shuffle=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectColumns(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def __init__(self, cols=[]):\n",
    "        self.cols = cols\n",
    "        \n",
    "    def fit(self, X=None, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        X = data.copy()\n",
    "        X = X[self.cols]   \n",
    "        return X\n",
    "    \n",
    "#select_columns(X_train, features_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.8519343413703855\n",
      "Test :  0.8512717824024411\n"
     ]
    }
   ],
   "source": [
    "##PIPELINE\n",
    "    #select features to modeling\n",
    "    #select model\n",
    "\n",
    "features_baseline = ['NewYear_Flag', 'MartinLutherKingDay_Flag','not delayed', 'delayed', 'unknown', \n",
    "                     'Duration_UTC_Standard', 'Distance_Standard']\n",
    "\n",
    "pipeline1 = Pipeline([(\"Select_Columns\", SelectColumns(cols = features_baseline)),\n",
    "                      (\"Model\", LogisticRegression())])\n",
    "\n",
    "pipeline1.fit(X_train, y_train)\n",
    "print('Train: ', pipeline1.score(X_train, y_train)) \n",
    "print('Test : ', pipeline1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.897309630840485\n",
      "Test :  0.8066461655820163\n"
     ]
    }
   ],
   "source": [
    "pipeline2 = Pipeline([(\"Select_Columns\", SelectColumns(cols = features_baseline)),\n",
    "                      (\"Model\", DecisionTreeClassifier())])\n",
    "\n",
    "pipeline2.fit(X_train, y_train)\n",
    "print('Train: ', pipeline2.score(X_train, y_train)) \n",
    "print('Test : ', pipeline2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.89727898106525\n",
      "Test :  0.8137579759549294\n"
     ]
    }
   ],
   "source": [
    "pipeline3 = Pipeline([(\"Select_Columns\", SelectColumns(cols = features_baseline)),\n",
    "                      (\"Model\", RandomForestClassifier())])\n",
    "\n",
    "pipeline3.fit(X_train, y_train)\n",
    "print('Train: ', pipeline3.score(X_train, y_train)) \n",
    "print('Test : ', pipeline3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.8519581800844571\n",
      "Test :  0.8512717824024411\n"
     ]
    }
   ],
   "source": [
    "pipeline4 = Pipeline([(\"Select_Columns\", SelectColumns(cols = features_baseline)),\n",
    "                      (\"Model\", GradientBoostingClassifier())])\n",
    "\n",
    "pipeline4.fit(X_train, y_train)\n",
    "print('Train: ', pipeline4.score(X_train, y_train)) \n",
    "print('Test : ', pipeline4.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.8522714888979703\n",
      "Test :  0.8502705666404443\n"
     ]
    }
   ],
   "source": [
    "pipeline5 = Pipeline([(\"Select_Columns\", SelectColumns(cols = features_baseline)),\n",
    "                      (\"Model\", KNeighborsClassifier(n_neighbors=10))])\n",
    "\n",
    "pipeline5.fit(X_train, y_train)\n",
    "print('Train: ', pipeline5.score(X_train, y_train)) \n",
    "print('Test : ', pipeline5.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'DATE_DEPARTURE_UTC', 'DATE_ARRIVAL_UTC', 'DATE_DEPARTURE_LCL',\n",
       "       'DATE_ARRIVAL_LCL', 'ORIGIN', 'DEST', 'OP_CARRIER',\n",
       "       'OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM', 'DISTANCE', 'DEP_DEL15',\n",
       "       'ARR_DEL15', 'DATE_ARRIVAL_UTC_ts', 'DATE_DEPARTURE_UTC_ts',\n",
       "       'DATE_ARRIVAL_LCL_ts', 'DATE_DEPARTURE_LCL_ts', 'WeekDay_DEPARTURE_UTC',\n",
       "       'WeekDay_ARRIVAL_UTC', 'DEP_DEL15_cat', 'not delayed', 'delayed',\n",
       "       'unknown', 'Duration_UTC', 'Duration_UTC_Standard', 'NewYear_Flag',\n",
       "       'MartinLutherKingDay_Flag', 'DISTANCE_noNaN', 'Distance_Standard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OneHotEncoder, TargetEncoder\n",
    "ohe = OneHotEncoder(use_cat_names=True, handle_missing = 'indicator', handle_unknown='indicator')\n",
    "\n",
    "ohe.fit(train[\"DEP_DEL15\"])\n",
    "\n",
    "x = ohe.transform(train[\"DEP_DEL15\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEP_DEL15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419482</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419483</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419484</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419485</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419486</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419487 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DEP_DEL15\n",
       "0             0.0\n",
       "1             NaN\n",
       "2             NaN\n",
       "3             0.0\n",
       "4             NaN\n",
       "...           ...\n",
       "419482        0.0\n",
       "419483        0.0\n",
       "419484        0.0\n",
       "419485        NaN\n",
       "419486        NaN\n",
       "\n",
       "[419487 rows x 1 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = OneHotEncoder(use_cat_names=True, handle_unknown='indicator')\n",
    "X = train[['DEP_DEL15']].squeeze()\n",
    "o.fit(X)\n",
    "X_ohe = o.transform(X) #Universe_-1 colummn is create for unseen categories\n",
    "X_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEP_DEL15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419482</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419483</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419484</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419485</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419486</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419487 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DEP_DEL15\n",
       "0             0.0\n",
       "1             NaN\n",
       "2             NaN\n",
       "3             0.0\n",
       "4             NaN\n",
       "...           ...\n",
       "419482        0.0\n",
       "419483        0.0\n",
       "419484        0.0\n",
       "419485        NaN\n",
       "419486        NaN\n",
       "\n",
       "[419487 rows x 1 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe2 = OneHotEncoder(handle_unknown='indicator',handle_missing = 'indicator')\n",
    "ohe2.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotEncoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
