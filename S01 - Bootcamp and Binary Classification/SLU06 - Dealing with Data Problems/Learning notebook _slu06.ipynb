{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLU06 - Dealing with Data Problems\n",
    "\n",
    "\n",
    "In this notebook we will be covering the following:\n",
    "\n",
    "- Tidy Data\n",
    "- Data Entry Problems\n",
    "- Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a real world scenario, data is almost never ready for applying modeling and/or visualisations.   \n",
    "There are a lot of work to be done before related to data cleaning.   \n",
    "This learning notebook covers the most common problems, related to  uncleaned data, and how to approach them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tidy Data\n",
    "\n",
    "\n",
    "Tidy datasets are easy to manipulate, model and visualize, and have a specific structure:\n",
    "* each variable is a column\n",
    "* each observation is a row\n",
    "* each type of observational unit is a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easier to explain the principle of Tidy Data by running through examples where this principle is violated, and seeing that following the structure described above yields a much cleaner dataset.\n",
    "\n",
    "The most common problems with messy datasets are the following:\n",
    "\n",
    "1) Column headers are values, not variable names;   \n",
    "2) Multiple variables are stored in one column;   \n",
    "3) Variables are stored in both rows and columns;   \n",
    "4) Multiple types of observational units are stored in the same table;   \n",
    "5) A single observational unit is stored in multiple tables;   \n",
    "\n",
    "\n",
    "In this notebook we will cover the problems number 1) and 4). If you want, you can check the other ones [here](https://vita.had.co.nz/papers/tidy-data.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem: Column headers are values, not variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>religion</th>\n",
       "      <th>&lt;$10k</th>\n",
       "      <th>$10-20k</th>\n",
       "      <th>$20-30k</th>\n",
       "      <th>$30-40k</th>\n",
       "      <th>$40-50k</th>\n",
       "      <th>$50-75k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agnostic</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atheist</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buddhist</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Catholic</td>\n",
       "      <td>418</td>\n",
       "      <td>617</td>\n",
       "      <td>732</td>\n",
       "      <td>670</td>\n",
       "      <td>638</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don’t know/refused</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Evangelical Prot</td>\n",
       "      <td>575</td>\n",
       "      <td>869</td>\n",
       "      <td>1064</td>\n",
       "      <td>982</td>\n",
       "      <td>881</td>\n",
       "      <td>1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hindu</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Historically Black Prot</td>\n",
       "      <td>228</td>\n",
       "      <td>244</td>\n",
       "      <td>236</td>\n",
       "      <td>238</td>\n",
       "      <td>197</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jehovah’s Witness</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jewish</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k\n",
       "0                 Agnostic     27       34       60       81       76      137\n",
       "1                  Atheist     12       27       37       52       35       70\n",
       "2                 Buddhist     27       21       30       34       33       58\n",
       "3                 Catholic    418      617      732      670      638     1116\n",
       "4       Don’t know/refused     15       14       15       11       10       35\n",
       "5         Evangelical Prot    575      869     1064      982      881     1486\n",
       "6                    Hindu      1        9        7        9       11       34\n",
       "7  Historically Black Prot    228      244      236      238      197      223\n",
       "8        Jehovah’s Witness     20       27       24       24       21       30\n",
       "9                   Jewish     19       19       25       25       30       95"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messy = pd.read_csv(os.path.join('data', 'column_headers_are_values.csv'), sep=' ')\n",
    "df_messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above dataset, we have two variables: `religion` and `income`.\n",
    "The Tidy Data principle is not being followed because the `income` variable is represented as multiple columns, instead of just one column.\n",
    "\n",
    "Using this data representation, it becomes kind of complicated to answer questions like \"How many people with the Buddhist religion earn between \\\\$10k and \\\\$40k?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many people with the Buddhist religion earn between $10k and $40k? - with messy data\n",
    "df_messy[df_messy.religion == 'Buddhist'][['$10-20k', '$20-30k', '$30-40k']].sum(axis=1).values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above query is a very unnatural one: first we're subsetting rows to get the right religion, then we subset columns to get the right income values, finally we do a messy sum to get the counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tidy up this data using method [`melt`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html), as shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income values stored in the columns:\n",
      "['<$10k', '$10-20k', '$20-30k', '$30-40k', '$40-50k', '$50-75k']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>religion</th>\n",
       "      <th>income</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agnostic</td>\n",
       "      <td>&lt;$10k</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atheist</td>\n",
       "      <td>&lt;$10k</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buddhist</td>\n",
       "      <td>&lt;$10k</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Catholic</td>\n",
       "      <td>&lt;$10k</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don’t know/refused</td>\n",
       "      <td>&lt;$10k</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             religion income  freq\n",
       "0            Agnostic  <$10k    27\n",
       "1             Atheist  <$10k    12\n",
       "2            Buddhist  <$10k    27\n",
       "3            Catholic  <$10k   418\n",
       "4  Don’t know/refused  <$10k    15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the income values from the column names, except 'religion'\n",
    "income_values = list(filter(lambda x: x != 'religion', df_messy.columns.tolist()))\n",
    "print(f\"Income values stored in the columns:\\n{income_values}\")\n",
    "\n",
    "# Using the melt function to 'melt' the income_values into a column\n",
    "df_tidy = pd.melt(df_messy, id_vars=['religion'], value_vars=income_values, var_name='income', value_name='freq')\n",
    "df_tidy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the column names, with exception of religion, are now the unique values of column `income`. We also have a new column named `freq`. On column `freq` it is represented the value that is on the same row and column of the correspondent `religion` and `income`, respectively, on DataFrame `df_messy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many people with the Buddhist religion earn between $10k and $40k? - with tidy data\n",
    "df_tidy[(df_tidy.religion == 'Buddhist') & (df_tidy.income.isin(['$10-20k', '$20-30k', '$30-40k']))].freq.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the query becomes easier to understand: first we subset the rows with the desired value for religion **AND** income, then we just sum the frequencies to get the final value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem: Multiple types of observational units are stored in the same table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "      <th>time</th>\n",
       "      <th>date.entered</th>\n",
       "      <th>wk1</th>\n",
       "      <th>wk2</th>\n",
       "      <th>wk3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2 Pac</td>\n",
       "      <td>Baby Don't Cry (Keep Ya Head Up II)</td>\n",
       "      <td>4:22</td>\n",
       "      <td>2000-02-26</td>\n",
       "      <td>87</td>\n",
       "      <td>82</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>2Ge+her</td>\n",
       "      <td>The Hardest Part Of Breaking Up (Is Getting Ba...</td>\n",
       "      <td>3:15</td>\n",
       "      <td>2000-09-02</td>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>3 Doors Down</td>\n",
       "      <td>Kryptonite</td>\n",
       "      <td>3:53</td>\n",
       "      <td>2000-04-08</td>\n",
       "      <td>81</td>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>A*Teens</td>\n",
       "      <td>Dancing Queen</td>\n",
       "      <td>3:44</td>\n",
       "      <td>2000-07-08</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>Aaliyah</td>\n",
       "      <td>I Don't Wanna</td>\n",
       "      <td>4:15</td>\n",
       "      <td>2000-01-29</td>\n",
       "      <td>84</td>\n",
       "      <td>62</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>Aaliyah</td>\n",
       "      <td>Try Again</td>\n",
       "      <td>4:03</td>\n",
       "      <td>2000-03-18</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000</td>\n",
       "      <td>Adams, Yolanda</td>\n",
       "      <td>Open My Heart</td>\n",
       "      <td>5:30</td>\n",
       "      <td>2000-08-26</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000</td>\n",
       "      <td>Aguilera, Christina</td>\n",
       "      <td>I Turn To You</td>\n",
       "      <td>4:00</td>\n",
       "      <td>2000-04-15</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year               artist  \\\n",
       "0  2000                2 Pac   \n",
       "1  2000              2Ge+her   \n",
       "2  2000         3 Doors Down   \n",
       "3  2000              A*Teens   \n",
       "4  2000              Aaliyah   \n",
       "5  2000              Aaliyah   \n",
       "6  2000       Adams, Yolanda   \n",
       "7  2000  Aguilera, Christina   \n",
       "\n",
       "                                               track  time date.entered  wk1  \\\n",
       "0                Baby Don't Cry (Keep Ya Head Up II)  4:22   2000-02-26   87   \n",
       "1  The Hardest Part Of Breaking Up (Is Getting Ba...  3:15   2000-09-02   91   \n",
       "2                                         Kryptonite  3:53   2000-04-08   81   \n",
       "3                                      Dancing Queen  3:44   2000-07-08   97   \n",
       "4                                      I Don't Wanna  4:15   2000-01-29   84   \n",
       "5                                          Try Again  4:03   2000-03-18   59   \n",
       "6                                      Open My Heart  5:30   2000-08-26   76   \n",
       "7                                      I Turn To You  4:00   2000-04-15   50   \n",
       "\n",
       "   wk2  wk3  \n",
       "0   82   72  \n",
       "1   87   92  \n",
       "2   70   68  \n",
       "3   97   96  \n",
       "4   62   51  \n",
       "5   53   38  \n",
       "6   76   74  \n",
       "7   39   30  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messy = pd.read_csv(os.path.join('data', 'multiple_types.csv'))\n",
    "df_messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, we have data from a music billboard: each observation is a song in the billboard, and the columns have information about the following variables:\n",
    "* `year` the billboard reports to\n",
    "* `artist`\n",
    "* `track` name\n",
    "* `time`, which is the track duration \n",
    "* `date.entered`, which is the date when the song entered the billboard\n",
    "* `wk1`, `wk2` and `wk3`: position of the song in the billboard per week of the year\n",
    "\n",
    "Now, the first problem that we can see is that the `wk1`, `wk2` and `wk3` all refer to the same variable, which is the position of the song in the billboard per week of the year. So we can take care of these like we did in the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "      <th>time</th>\n",
       "      <th>date.entered</th>\n",
       "      <th>week</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2 Pac</td>\n",
       "      <td>Baby Don't Cry (Keep Ya Head Up II)</td>\n",
       "      <td>4:22</td>\n",
       "      <td>2000-02-26</td>\n",
       "      <td>wk1</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000</td>\n",
       "      <td>2 Pac</td>\n",
       "      <td>Baby Don't Cry (Keep Ya Head Up II)</td>\n",
       "      <td>4:22</td>\n",
       "      <td>2000-02-26</td>\n",
       "      <td>wk2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2000</td>\n",
       "      <td>2 Pac</td>\n",
       "      <td>Baby Don't Cry (Keep Ya Head Up II)</td>\n",
       "      <td>4:22</td>\n",
       "      <td>2000-02-26</td>\n",
       "      <td>wk3</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>2Ge+her</td>\n",
       "      <td>The Hardest Part Of Breaking Up (Is Getting Ba...</td>\n",
       "      <td>3:15</td>\n",
       "      <td>2000-09-02</td>\n",
       "      <td>wk1</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000</td>\n",
       "      <td>2Ge+her</td>\n",
       "      <td>The Hardest Part Of Breaking Up (Is Getting Ba...</td>\n",
       "      <td>3:15</td>\n",
       "      <td>2000-09-02</td>\n",
       "      <td>wk2</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2000</td>\n",
       "      <td>2Ge+her</td>\n",
       "      <td>The Hardest Part Of Breaking Up (Is Getting Ba...</td>\n",
       "      <td>3:15</td>\n",
       "      <td>2000-09-02</td>\n",
       "      <td>wk3</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>3 Doors Down</td>\n",
       "      <td>Kryptonite</td>\n",
       "      <td>3:53</td>\n",
       "      <td>2000-04-08</td>\n",
       "      <td>wk1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2000</td>\n",
       "      <td>3 Doors Down</td>\n",
       "      <td>Kryptonite</td>\n",
       "      <td>3:53</td>\n",
       "      <td>2000-04-08</td>\n",
       "      <td>wk2</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2000</td>\n",
       "      <td>3 Doors Down</td>\n",
       "      <td>Kryptonite</td>\n",
       "      <td>3:53</td>\n",
       "      <td>2000-04-08</td>\n",
       "      <td>wk3</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>A*Teens</td>\n",
       "      <td>Dancing Queen</td>\n",
       "      <td>3:44</td>\n",
       "      <td>2000-07-08</td>\n",
       "      <td>wk1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year        artist                                              track  \\\n",
       "0   2000         2 Pac                Baby Don't Cry (Keep Ya Head Up II)   \n",
       "8   2000         2 Pac                Baby Don't Cry (Keep Ya Head Up II)   \n",
       "16  2000         2 Pac                Baby Don't Cry (Keep Ya Head Up II)   \n",
       "1   2000       2Ge+her  The Hardest Part Of Breaking Up (Is Getting Ba...   \n",
       "9   2000       2Ge+her  The Hardest Part Of Breaking Up (Is Getting Ba...   \n",
       "17  2000       2Ge+her  The Hardest Part Of Breaking Up (Is Getting Ba...   \n",
       "2   2000  3 Doors Down                                         Kryptonite   \n",
       "10  2000  3 Doors Down                                         Kryptonite   \n",
       "18  2000  3 Doors Down                                         Kryptonite   \n",
       "3   2000       A*Teens                                      Dancing Queen   \n",
       "\n",
       "    time date.entered week  position  \n",
       "0   4:22   2000-02-26  wk1        87  \n",
       "8   4:22   2000-02-26  wk2        82  \n",
       "16  4:22   2000-02-26  wk3        72  \n",
       "1   3:15   2000-09-02  wk1        91  \n",
       "9   3:15   2000-09-02  wk2        87  \n",
       "17  3:15   2000-09-02  wk3        92  \n",
       "2   3:53   2000-04-08  wk1        81  \n",
       "10  3:53   2000-04-08  wk2        70  \n",
       "18  3:53   2000-04-08  wk3        68  \n",
       "3   3:44   2000-07-08  wk1        97  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_vars = ['year', 'artist', 'track', 'time', 'date.entered']\n",
    "value_vars = ['wk1', 'wk2', 'wk3']\n",
    "df_melted = pd.melt(df_messy, id_vars=id_vars, value_vars=value_vars, var_name='week', value_name='position')\n",
    "df_melted.sort_values(['artist', 'week']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the problem that we can see here is that we're trying to represent two observational units in the same table: one is the song itself, the other is its billboard position in a certain point in time.\n",
    "\n",
    "It is better to split these two types of observational units into two tables. However, we should have a way to relate both. We need to mantain a correspondence, a mapping id, for these two tables. If in future, we need to put the pieces together, with a mapping id we are able to join again the DataFrames. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the main table doesn't have any unique id, we need to create one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "      <th>time</th>\n",
       "      <th>date.entered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2 Pac</td>\n",
       "      <td>Baby Don't Cry (Keep Ya Head Up II)</td>\n",
       "      <td>4:22</td>\n",
       "      <td>2000-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2Ge+her</td>\n",
       "      <td>The Hardest Part Of Breaking Up (Is Getting Ba...</td>\n",
       "      <td>3:15</td>\n",
       "      <td>2000-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>3 Doors Down</td>\n",
       "      <td>Kryptonite</td>\n",
       "      <td>3:53</td>\n",
       "      <td>2000-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>A*Teens</td>\n",
       "      <td>Dancing Queen</td>\n",
       "      <td>3:44</td>\n",
       "      <td>2000-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "      <td>Aaliyah</td>\n",
       "      <td>I Don't Wanna</td>\n",
       "      <td>4:15</td>\n",
       "      <td>2000-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>Aaliyah</td>\n",
       "      <td>Try Again</td>\n",
       "      <td>4:03</td>\n",
       "      <td>2000-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2000</td>\n",
       "      <td>Adams, Yolanda</td>\n",
       "      <td>Open My Heart</td>\n",
       "      <td>5:30</td>\n",
       "      <td>2000-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2000</td>\n",
       "      <td>Aguilera, Christina</td>\n",
       "      <td>I Turn To You</td>\n",
       "      <td>4:00</td>\n",
       "      <td>2000-04-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id  year               artist  \\\n",
       "0        0  2000                2 Pac   \n",
       "1        1  2000              2Ge+her   \n",
       "2        2  2000         3 Doors Down   \n",
       "3        3  2000              A*Teens   \n",
       "4        4  2000              Aaliyah   \n",
       "5        5  2000              Aaliyah   \n",
       "6        6  2000       Adams, Yolanda   \n",
       "7        7  2000  Aguilera, Christina   \n",
       "\n",
       "                                               track  time date.entered  \n",
       "0                Baby Don't Cry (Keep Ya Head Up II)  4:22   2000-02-26  \n",
       "1  The Hardest Part Of Breaking Up (Is Getting Ba...  3:15   2000-09-02  \n",
       "2                                         Kryptonite  3:53   2000-04-08  \n",
       "3                                      Dancing Queen  3:44   2000-07-08  \n",
       "4                                      I Don't Wanna  4:15   2000-01-29  \n",
       "5                                          Try Again  4:03   2000-03-18  \n",
       "6                                      Open My Heart  5:30   2000-08-26  \n",
       "7                                      I Turn To You  4:00   2000-04-15  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In one table we store the songs, and give it an id\n",
    "df_messy['song_id'] = range(len(df_messy))\n",
    "df_songs = df_messy[['song_id'] + id_vars]\n",
    "df_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>week</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>wk1</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>wk2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>wk3</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wk1</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>wk2</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id week  position\n",
       "0        0  wk1        87\n",
       "1        0  wk2        82\n",
       "2        0  wk3        72\n",
       "3        1  wk1        91\n",
       "4        1  wk2        87"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the other table, we keep the positions per week and the song_id\n",
    "df_positions = pd.melt(df_messy, id_vars=['song_id'], value_vars=value_vars, var_name='week', value_name='position')\n",
    "df_positions = df_positions.sort_values(['song_id', 'week']).reset_index(drop=True)\n",
    "df_positions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Entry Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ilustrate what those problems look like, let's upload the following DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 200 observations.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CFLOXRHMDR</th>\n",
       "      <td>88.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FXLJSNLSOG</th>\n",
       "      <td>29.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FWDIVJKGOI</th>\n",
       "      <td>42.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YWEBKQWHRE</th>\n",
       "      <td>25.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YPUQAPSOYJ</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YPUQAPSOYJ</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YPUQAPSOYJ</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YPUQAPSOYJ</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSZQEGTLNK</th>\n",
       "      <td>NaN</td>\n",
       "      <td>162.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRFEFXNGWN</th>\n",
       "      <td>36.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  height  gender\n",
       "CFLOXRHMDR  88.0   163.0  female\n",
       "FXLJSNLSOG  29.0   158.0  female\n",
       "FWDIVJKGOI  42.0   159.0  female\n",
       "YWEBKQWHRE  25.0   179.0    male\n",
       "YPUQAPSOYJ  32.0   169.0    male\n",
       "YPUQAPSOYJ  32.0   169.0    male\n",
       "YPUQAPSOYJ  32.0   169.0    male\n",
       "YPUQAPSOYJ  32.0   169.0    male\n",
       "SSZQEGTLNK   NaN   162.0    male\n",
       "PRFEFXNGWN  36.0   166.0  female"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join('data', 'data_with_problems.csv'), index_col=0)\n",
    "print(f\"This dataset has {len(data)} observations.\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this DataFrame, we have:\n",
    "* 3 variables: `age`, `height` and `gender`. The first two are `numerical` variables while the last one is `categorical`.\n",
    "* 200 observations\n",
    "\n",
    "As the Tidy Data guidelines suggest, we have each of these variables in a column of our DataFrame, so we're good.\n",
    "\n",
    "Based on the names of our variables, we can conclude that each row (observation) represents a person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data entry problems** usually occur when an agent (usually a dumb human!) is transcribing information into an electronic medium.\n",
    "\n",
    "Typical data entry problems are:\n",
    "- Case mismatches in text fields\n",
    "- Grammar errors (_typos_) in text fields\n",
    "- Wrong data types\n",
    "- Non-sense values (or “I really don’t know what to write here but this form forces me to write something...”)\n",
    "- Missing values\n",
    "- Duplicated observations\n",
    "- and a lot more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](media/cat_typing.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These problems need to be resolved before jumping in a more analytical process, if not, it can lead to not accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data entry problems in categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our categorical feature `gender`, using two functions: [value_counts](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) and [nunique](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.nunique.html).\n",
    "\n",
    "With `nunique` method we can get the number of unique values found in this `pd.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gender.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there are 7 unique values for gender, which is unexpected...\n",
    "\n",
    "Using `value_counts` method, we can get counts per unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female       109\n",
       "male          66\n",
       "MALE           9\n",
       "m              3\n",
       "F              2\n",
       "f              1\n",
       "   female      1\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it seems that for most of the observations we have `gender` with values female or male, but there are some cases where we have different values: MALE, m, F, f,    female (with leading blank spaces).\n",
    "\n",
    "To clean this data, we can do **string manipulation** directly on the DataFrame!\n",
    "We can apply a python string method to all the elements in a pandas Series by calling `.str` on the Series, followed by the string method.\n",
    "\n",
    "For instance, let's convert all the strings in the `gender` column to lower case, using [`str.lower`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.lower.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female       109\n",
       "male          75\n",
       "f              3\n",
       "m              3\n",
       "   female      1\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gender = data.gender.str.lower()\n",
    "data.gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this converted all the cases of `MALE` (which were 9) to `male` (before: 66 observations, after: 75 observations).\n",
    "\n",
    "Also, all the cases of `F` (which were 2), were converted to `f` (before: 1 observation, after: 3 observations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not super useful in this context, but still worth mentioning that [`str.lower`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.lower.html) has a sister, called [`str.upper`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.upper.html), that does exactly the opposite: converts the strings to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FEMALE       109\n",
       "MALE          75\n",
       "M              3\n",
       "F              3\n",
       "   FEMALE      1\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gender.str.upper().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean this data a bit more: using [`str.strip`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.strip.html), we'll remove leading and trailing whitespaces from the strings in the `gender` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    110\n",
       "male       66\n",
       "MALE        9\n",
       "m           3\n",
       "F           2\n",
       "f           1\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gender = data.gender.str.strip()\n",
    "data.gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string `female` with leading whitespaces was converted to `female`, without the whitespaces!\n",
    "\n",
    "Next we need to replace `m` with `male` and `f` with `female`.\n",
    "We can do that using the [`str.replace`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.replace.html) method, that receives as arguments a pattern and a replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "femaleale    110\n",
       "maleale       75\n",
       "f              3\n",
       "male           3\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that here we're not changing the values in data.gender, we're just outputting them!\n",
    "data.gender.str.replace('m', 'male').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait... something is weird!\n",
    "\n",
    "What happens is that str.replace replaces **any** occurrences of the pattern in the Series values, even if they appear in the middle of something!\n",
    "We can fix this in two ways.\n",
    "\n",
    "**First option**: the pattern received by str.replace can be a **regex**. Using a regex, we can specify that we want to replace the string `m` with `male`, but only when it appears alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    110\n",
       "male       78\n",
       "f           3\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gender.str.replace('^m$', 'male').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can chain two of these operations together in order to handle the two replacements at the same time.\n",
    "Notice that we need to call `.str` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    113\n",
       "male       78\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gender.str.replace('^m$', 'male').str.replace('^f$', 'female').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second option**: instead of using the [`str.replace`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.replace.html) method, we can use the [`replace`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.replace.html) method, that receives as argument a dictionary with the full-word replacements we want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    113\n",
       "male       78\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gender = data.gender.replace({'m': 'male', 'f': 'female'})\n",
    "data.gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gender` variable is looking better!\n",
    "\n",
    "Now, if you noticed at the beginning of the notebook, we counted 200 observations in our dataset. However `113 + 78 = 191`...\n",
    "\n",
    "The problem we have here is that the [`value_counts`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) method doesn't count null values by default. If we want to count those, we need to set the argument `dropna=False`.\n",
    "\n",
    "Let's see how to do that and also how to visualise the value counts using a barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZpUlEQVR4nO3de7gkdX3n8fdHBuQuILOEm44XhBCioiNojAmrJl4TiEGEFQVFiSZeEzdisq7EK+66UZFogogMCSKICihegii6qKCDEhCQyHKRwUFGuYgoIvrdP+p3yubQh+kzTJ8+M+f9ep5+prqq+lffqq7pT9WvuuukqpAkCeB+ky5AkjR/GAqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hsB5KUkkePuk65rN0Ppzk5iTfGPE1JyR567hrm60kD0ry0yQbjDDvPklW3Mv0ebmOo1iXa59PDIV5KMnnkrx5yPh9k9yQZNEk6pqEJOcmeckYmv594I+AnapqryHLPTTJeWNY7lpXVd+vqs2r6leTrCNJtX/PTbLPJGtZE0muSbKkhcuhk65nUgyF+WkZcHCSTBv/AuCkqrprAjWtbx4MXFNVt0+6kPtiIR0gjIvb8O4MhfnpdOCBwJOmRiTZGng2cGKSvZJ8PcktSVYmOSbJRsMamn6kPf0IOMluSc5OclOSK5IcMFNRSbZpXS4/aN0upw9Me2mSK1s7ZybZoY1f0rqzFg3M29c0VU+Sd7U2r07yjDbtbW0bHNO6R45p3T7vTnJjkp8kuSTJHjPUu0Or5aZW20vb+MOA44AntHb/Ydrrfhv454HptwxM3jrJWUluS3JBkofNdlsmeV6S5dPGvTbJmW34WUm+3dbvuiRHDsw3tT0PS/J94IvTt3GSFyW5vNV4VZK/GFLD3yX5UTs6fv6wOtt8z05yUdvXvpbkkTPNO8PrN0myrL23lyf52wx0X7X36ONJVrX3/lUD045McmqSE9u6XJpk6cD0PZN8q007Bdh41Nrber8+ycXA7TEYfqOqfMzDB/BB4LiB538BXNSGHws8HlgELAEuB14zMG8BD2/D5wIvGZh2KHBeG94MuA54UWtrT+BHwO4z1HQWcAqwNbAh8Idt/JPb6x4D3B94H/CVNm1Jq2fRQDt9Ta2eXwIvBTYAXg78AMgM9T8NuBDYCgjw28D2M9T7FeD9dB8WjwZWAU+evh1meO09pgMnAD8G9mrb6yTgo7PdlsCmwG3ALgPjvgkc2Ib3AX6X7qDtkcAPgf2mbc8T2zI3mb6NgWcBD2vb5w+BnwGPGWj7LuAf23v1h8DtwK4D6/jWNrwncCOwd3tvDgGuAe4/i/34KODLbZ/ZCbgYWNGm3a+9l/8T2Ah4KHAV8LQ2/UjgDuCZbfnvAM5v0zYCrgVeS7cv7k+3H41Uexu+CNgZ2GTS/9/n08MzhflrGbB/kqmjnxe2cVTVhVV1flXdVVXXAP9C9597tp5N14Xy4dbWt4GPA8+dPmOS7YFnAC+rqpur6pdV9eU2+fnA8VX1rar6BfAGuqPsJSPWcW1VfbC6PvFlwPbAdjPM+0tgC2A3uuC4vKpWDql3Z+CJwOur6o6quoju7OCFI9Y0k09W1Teq68I7iS5sYBbbsqp+BpwBHNRq3aWtz5lt+rlVdUlV/bqqLgZO5p7v75FVdXtV/XxI+2dV1f+rzpeBf2fgrLN5Y1X9ok0/Cxh2VnM48C9VdUFV/aqqlgG/oDsgGdUBwNvbPrMCOHpg2uOAxVX15qq6s6quojsYOnBgnvOq6jNt3/hX4FFt/OPpwuA9bV88jS5YZ1P70VV13bBtuJAZCvNUVZ1Hd6S5X+ui2Av4CECSRyT5dLqLzj8B3g5suwaLeTCwdzu9vqV1kzwf+K0h8+4M3FRVNw+ZtgPdUdtU7T+lO6LeccQ6bhh47c/a4ObDZqyqLwLHAP8E3Jjk2CRbzlDTTVV128C4a2dR02prpTsCn6pzNtsSuvfyoDb834DTp9Y9yd5JvtS6VG4FXsY939/rZiowyTOSnN+6sW6hO9IefP3NdfdrKdfSba/pHgz8zbR12nmGeWeyw7RaB4cfDOwwrf2/4+4HBNO398atq2cH4PqqGryj57UDw6PUPuM2XMgMhfntRLoj24OBz1fVD9v4DwDfpet+2JLuP9L0i9JTbqfrrpgy+CF1HfDlqtpq4LF5Vb18SDvXAdsk2WrItB/Q/ScEIMlmdNdErm/L515qWJ173Ma3qo6uqscCuwOPAP77DDVtk2SLgXEPajWt0XJXYzbbEuBsYHGSR9OFw0cGpn2E7qxh56p6AN31jenv79D6ktyf7gzlXcB2VbUV8Jlpr9+6vUdTHkS3vYat09umrdOmVXXyDOs0zEq6bqMpO09r/+pp7W9RVc8csd0dk7t9GeNBs6zdW0QPYSjMbycCT6Xrb182MH4L4CfAT5PsRtcPP5OLgOck2TTdbxcOG5j2aeARSV6QZMP2eFy70Ho3rYvms8D7k2zd5v2DNvlk4EVJHt0+lN4OXFBV11TVKroP4oOTbJDkxXT93aP6IV1fMwCtvr2TbEgXOHcAvx5S73XA14B3JNm4XWQ8DPi3WSx3p8xwAX+Ikbdlq++XwMeA/w1sQxcSU7agO8u5I8ledGcSo9qI7lrBKuCudBft/3jIfP+QZKMkT6Lr+vrYkHk+CLysbe8k2SzdRfAthsw7k1OBN7R9ZkfgFQPTvgHc1i74btL2jz2SPG6Edr9Od23kVW1bP4fubHpt1r4gGQrzWLte8DW6C4pnDkx6Hd0HxW10O/8p99LMu4E76T7kltH1g0+1fxvdB8aBdEeKNwDvpPtQGeYFdH3636W7iPea1s4XgDfSHaGupPvQH+wXfind0fyPgd9p6zSq99JdW7k5ydHAlnTrfDNdd8GP6T5YhzmI7iLsD4BPAm9qtY7ii8ClwA1JfrS6mddgW0J3RvBU4GN1968Z/yXw5iS30V2EPXXEmqfqeFV7zc10+8mZ02a7oU37Ad3+8LKq+u6QtpbTvXfHtPmvpLsAPxtvBlYAVwNfAE6j69unXSd4Nt11mavpukuPAx6wukar6k7gOa2em4DnAZ9Yy7UvSFPf8JCksUvycrpvWa3JFyM0BzxTkDQ2SbZP8sQk90uyK/A3dGdtmqf8wYakcdqI7ivTDwFuAT5K99sRzVN2H0mSenYfSZJ663T30bbbbltLliyZdBmStE658MILf1RVi4dNW6dDYcmSJSxfvnz1M0qSekmunWma3UeSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpN46/Yvm2VpyxFljbf+ao5411vYladw8U5Ak9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVJvbKGQ5PgkNyb5zsC4bZKcneR77d+t2/gkOTrJlUkuTvKYcdUlSZrZOM8UTgCePm3cEcA5VbULcE57DvAMYJf2OBz4wBjrkiTNYGyhUFVfAW6aNnpfYFkbXgbsNzD+xOqcD2yVZPtx1SZJGm6urylsV1Ur2/ANwHZteEfguoH5VrRxkqQ5NLELzVVVQM32dUkOT7I8yfJVq1aNoTJJWrjmOhR+ONUt1P69sY2/Hth5YL6d2rh7qKpjq2ppVS1dvHjxWIuVpIVmrkPhTOCQNnwIcMbA+Be2byE9Hrh1oJtJkjRHFo2r4SQnA/sA2yZZAbwJOAo4NclhwLXAAW32zwDPBK4Efga8aFx1SZJmNrZQqKqDZpj0lCHzFvBX46pFkjQaf9EsSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSepNJBSSvDbJpUm+k+TkJBsneUiSC5JcmeSUJBtNojZJWsjmPBSS7Ai8ClhaVXsAGwAHAu8E3l1VDwduBg6b69okaaGbVPfRImCTJIuATYGVwJOB09r0ZcB+E6pNkhasOQ+FqroeeBfwfbowuBW4ELilqu5qs60Adhz2+iSHJ1meZPmqVavmomRJWjAm0X20NbAv8BBgB2Az4Omjvr6qjq2qpVW1dPHixWOqUpIWpkl0Hz0VuLqqVlXVL4FPAE8EtmrdSQA7AddPoDZJWtAmEQrfBx6fZNMkAZ4CXAZ8Cdi/zXMIcMYEapOkBW0S1xQuoLug/C3gklbDscDrgb9OciXwQOBDc12bJC10i1Y/y9pXVW8C3jRt9FXAXhMoR5LU+ItmSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVJv0aQL0OiWHHHWWNu/5qhnjbV9SfOfZwqSpJ6hIEnqGQqSpN5IoZDknFHGSZLWbfd6oTnJxsCmwLZJtgbSJm0J7Djm2iRJc2x13z76C+A1wA7AhfwmFH4CHDPGuiRJE3CvoVBV7wXem+SVVfW+OapJkjQhI/1Ooarel+T3gCWDr6mqE9dkoUm2Ao4D9gAKeDFwBXBKW8Y1wAFVdfOatC9JWjOjXmj+V+BdwO8Dj2uPpfdhue8FPldVuwGPAi4HjgDOqapdgHPac0nSHBr1F81Lgd2rqu7rApM8APgD4FCAqroTuDPJvsA+bbZlwLnA6+/r8iRJoxv1dwrfAX5rLS3zIcAq4MNJvp3kuCSbAdtV1co2zw3AdsNenOTwJMuTLF+1atVaKkmSBKOHwrbAZUk+n+TMqccaLnMR8BjgA1W1J3A707qK2hnJ0LOSqjq2qpZW1dLFixevYQmSpGFG7T46ci0ucwWwoqouaM9PowuFHybZvqpWJtkeuHEtLlOSNIJRv3305bW1wKq6Icl1SXatqiuApwCXtcchwFHt3zPW1jIlSaMZKRSS3MZvunM2AjYEbq+qLddwua8ETkqyEXAV8CK6rqxTkxwGXAscsIZtS5LW0KhnCltMDScJsC/w+DVdaFVdxPCvtD5lTduUJN13s75LanVOB542hnokSRM0avfRcwae3o/uKP+OsVQkSZqYUb999CcDw3fR3YZi37VejSRpoka9pvCicRciSZq8Ue99tFOSTya5sT0+nmSncRcnSZpbo15o/jBwJt3fVdgB+FQbJ0laj4waCour6sNVdVd7nAB4jwlJWs+MGgo/TnJwkg3a42Dgx+MsTJI090YNhRfT/cL4BmAlsD/t1teSpPXHqF9JfTNwyNRfQkuyDd0f3XnxuAqTJM29Uc8UHjn4pzGr6iZgz/GUJEmalFFD4X5Jtp560s4URj3LkCStI0b9YP8/wNeTfKw9fy7wtvGUJEmalFF/0XxikuXAk9uo51TVZeMrS5I0CSN3AbUQMAgkaT0261tnS5LWX4aCJKlnKEiSeoaCJKlnKEiSeoaCJKlnKEiSeoaCJKlnKEiSeoaCJKlnKEiSeoaCJKlnKEiSehMLhSQbJPl2kk+35w9JckGSK5OckmSjSdUmSQvVJM8UXg1cPvD8ncC7q+rhwM3AYROpSpIWsImEQpKdgGcBx7XnofsDPqe1WZYB+02iNklayCZ1pvAe4G+BX7fnDwRuqaq72vMVwI7DXpjk8CTLkyxftWrV+CuVpAVkzkMhybOBG6vqwjV5fVUdW1VLq2rp4sWL13J1krSwjfznONeiJwJ/muSZwMbAlsB7ga2SLGpnCzsB10+gNkla0Ob8TKGq3lBVO1XVEuBA4ItV9XzgS8D+bbZDgDPmujZJWujm0+8UXg/8dZIr6a4xfGjC9UjSgjOJ7qNeVZ0LnNuGrwL2mmQ9krTQzaczBUnShBkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6s15KCTZOcmXklyW5NIkr27jt0lydpLvtX+3nuvaJGmhm8SZwl3A31TV7sDjgb9KsjtwBHBOVe0CnNOeS5Lm0JyHQlWtrKpvteHbgMuBHYF9gWVttmXAfnNdmyQtdBO9ppBkCbAncAGwXVWtbJNuALab4TWHJ1meZPmqVavmpE5JWigmFgpJNgc+Drymqn4yOK2qCqhhr6uqY6tqaVUtXbx48RxUKkkLx0RCIcmGdIFwUlV9oo3+YZLt2/TtgRsnUZskLWST+PZRgA8Bl1fVPw5MOhM4pA0fApwx17VJ0kK3aALLfCLwAuCSJBe1cX8HHAWcmuQw4FrggAnUJkkL2pyHQlWdB2SGyU+Zy1okSXfnL5olST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkSb1J/JEdLVBLjjhrrO1fc9Szxtr+OOsfd+3SqDxTkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs/bXEgLwLp+ixHNHc8UJEk9zxQkzXue6cydeXWmkOTpSa5IcmWSIyZdjyQtNPPmTCHJBsA/AX8ErAC+meTMqrpsspVJ0n2zLp3pzKczhb2AK6vqqqq6E/gosO+Ea5KkBSVVNekaAEiyP/D0qnpJe/4CYO+qesW0+Q4HDm9PdwWuGGNZ2wI/GmP742b9k7Mu1w7WP2njrv/BVbV42IR50300qqo6Fjh2LpaVZHlVLZ2LZY2D9U/Oulw7WP+kTbL++dR9dD2w88Dzndo4SdIcmU+h8E1glyQPSbIRcCBw5oRrkqQFZd50H1XVXUleAXwe2AA4vqounXBZc9JNNUbWPznrcu1g/ZM2sfrnzYVmSdLkzafuI0nShBkKkqTeeh0KSV6V5PIkJ42p/SOTvG4cba9tSfZJ8ukJLr+S/NvA80VJVk2vKcnpSc6fNm7odk7yqyQXDTy8NcoCN2SfWDLpmmZr3J9bqzNvLjSPyV8CT62qFZMuRNwO7JFkk6r6Od3tTO72leMkWwGPBX6a5KFVddVq2vx5VT16POVqHbU+7BMT/dxab88Ukvwz8FDgs0n+PsnxSb6R5NtJ9m3zHNqOTM9Ock2SVyT56zbP+Um2afO9NMk3k/xHko8n2XTI8h6W5HNJLkzyf5PsNoZ1WpLku0lOSPKfSU5K8tQkX03yvSR7tcfX2zp8LcmuQ9rZbNj2mAOfAaZu0nIQcPK06c8BPkV3i5MD56imNdLei8uTfDDJpUn+PckmM+0r7T07ur0nV7Vf8M8bo+xbk65xIZj2ufXaiRRRVevtA7iG7ufibwcObuO2Av4T2Aw4FLgS2AJYDNwKvKzN927gNW34gQNtvhV4ZRs+EnhdGz4H2KUN7w18cQzrswS4C/hdukC/EDgeCN19ok4HtgQWtfmfCny8De8DfLoND90eY34vfgo8EjgN2Bi4aLCmNs/ZwJOARwCXDIzvt/O0Nn/V2pl6PG8O962p9+LR7fmpwMH3sq+cAHysvW+7093na+L/R2azb026xhHXY3Cf+OSk61nDdbgG2HZSy1/fu4+m/DHwpwP90hsDD2rDX6qq24DbktxKd6QKcAndhxh03R5vpfsA3ZzutxS9JJsDvwd8LMnU6PuPY0WAq6vqkrbcS4FzqqqSXEL3H/sBwLIkuwAFbDikjZm2x+VjqhmAqrq49fEeRHfW0EuyHbALcF5bn18m2aOqvnMvTU66q+DqqrqoDV9It/3vbV85vap+DVzW1ne+Wd2+tS6Y9D6xzlsooRDgz6vqbjfPS7I38IuBUb8eeP5rfrN9TgD2q6r/SHIo3RHuoPsBt8zRzri6et9CF3R/1j6Azx3SxtDtMUfOBN5Ftw0fODD+AGBr4OoWrFvShcffz3F9szH4XvwK2IR731cG5w/zzyj/F7SeW2+vKUzzeeCVaZ82Sfac5eu3AFYm2RB4/vSJVfUTug+z57b2k+RR97HmNfUAfnMB99AZ5rmv2+O+OB74h6kj0gEH0d0ld0lVLaG74DyvryvM4F73FWm+Wyih8Ba6bpSL22nxW2b5+jcCFwBfBb47wzzPBw5L8h/ApUzub0H8L+AdSb7NzEd393V7rLGqWlFVRw+Oa2c0DwbOH5jvauDWdjYH8D+SrJh6tHGbTPv64VFzsAqrM8q+Is1b3uZCktRbKGcKkqQRGAqSpJ6hIEnqGQqSpJ6hIEnqGQrSHGn3FZpX9zySpjMUpHkqib8i1pwzFKQhkrwxyRVJzktycpLXzXQn3JnugNp+2X5Ma+cLwH8ZaP+xSb7c2vp8ku3b+HOTvCfJcuDVk1h3LWweiUjTJHkc8OfAo+h++f0tuhveHUt3F93vtV9avx94cnvZ9sDvA7vR3d/pNODPgF3p7oq6HXAZcHy7Bcb7gH2ralWS5wFvA17c2tqoqpaOfUWlIQwF6Z6eCJxRVXcAdyT5FN2dZO/tTrjD7oD6B8DJVfUr4AdJvtjG7wrsAZzd2toAWDnQ1iljWCdpJIaCNJrV3Ql3NndADXBpVT1hhum3z7Y4aW3xmoJ0T18F/iTJxu1vZTwb+BmzvxPuV4DnJdmgXTP4r238FcDiJE9obW2Y5HfGsibSLBkK0jRV9U266wIXA5+l+4NLtzL7O+F+Evge3bWEE4Gvt/bvBPYH3tnauoiua0qaOO+SKg2RZPOq+mn7G8tfAQ6vqm9Nui5p3LymIA13bJLd6S4wLzMQtFB4piBJ6nlNQZLUMxQkST1DQZLUMxQkST1DQZLU+/9cvNpCj6IaSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.gender.value_counts(dropna=False).plot(kind='bar', rot=0)\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('gender')\n",
    "plt.title('Value counts of the variable \"gender\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen how to use some string methods directly on Series. There are many more string methods available, but we'll just see two more useful methods, which are [`str.cat`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.cat.html) and [`str.split`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html).\n",
    "\n",
    "Say we had a birthdate column in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1942-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1946-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1946-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1947-08-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1954-01-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  height  gender   birthdate\n",
       "0  88.0   163.0  female  1942-02-27\n",
       "1  29.0   158.0  female  1946-03-31\n",
       "2  42.0   159.0  female  1946-09-13\n",
       "3  25.0   179.0    male  1947-08-25\n",
       "4  32.0   169.0    male  1954-01-24"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_bd = pd.read_csv(os.path.join('data', 'data_with_problems_and_birthdays.csv'))\n",
    "data_with_bd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use the [`str.split`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html) method to split the date into year, month and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1942</td>\n",
       "      <td>02</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1946</td>\n",
       "      <td>03</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1946</td>\n",
       "      <td>09</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1947</td>\n",
       "      <td>08</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954</td>\n",
       "      <td>01</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month day\n",
       "0  1942    02  27\n",
       "1  1946    03  31\n",
       "2  1946    09  13\n",
       "3  1947    08  25\n",
       "4  1954    01  24"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = data_with_bd.birthdate.str.split(pat='-', expand=True)\n",
    "dates.columns = ['year', 'month', 'day']\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we could merge it back together with [`str.cat`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.cat.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>moth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1942</td>\n",
       "      <td>02</td>\n",
       "      <td>27</td>\n",
       "      <td>02/1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1946</td>\n",
       "      <td>03</td>\n",
       "      <td>31</td>\n",
       "      <td>03/1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1946</td>\n",
       "      <td>09</td>\n",
       "      <td>13</td>\n",
       "      <td>09/1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1947</td>\n",
       "      <td>08</td>\n",
       "      <td>25</td>\n",
       "      <td>08/1947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954</td>\n",
       "      <td>01</td>\n",
       "      <td>24</td>\n",
       "      <td>01/1954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month day moth_year\n",
       "0  1942    02  27   02/1942\n",
       "1  1946    03  31   03/1946\n",
       "2  1946    09  13   09/1946\n",
       "3  1947    08  25   08/1947\n",
       "4  1954    01  24   01/1954"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates['moth_year'] = dates.month.str.cat(dates.year, sep='/')\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data entry problems in numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data entry problems can also happen in numerical variables.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to `data` DataFrame and look closely to feature `age`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having this page as a baseline [oldest person ever](https://www.guinnessworldrecords.com/world-records/oldest-person), let's set the maximum possible age at 123, and the lowest at 0.   \n",
    "Let's see if there are any values out of this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSHRBGFOJU    300000000.0\n",
       "SQYVEHAWSW          224.0\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.age[(data.age<0) | (data.age>123)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can handle these values as if they were missing values. For that purpose, let's replace these values with `np.nan`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSHRBGFOJU</th>\n",
       "      <td>NaN</td>\n",
       "      <td>184.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQYVEHAWSW</th>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  height  gender\n",
       "TSHRBGFOJU  NaN   184.0  female\n",
       "SQYVEHAWSW  NaN   166.0    male"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(data.age<0) | (data.age>123), \"age\"] = np.nan\n",
    "data.loc[[\"TSHRBGFOJU\", \"SQYVEHAWSW\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: On section 3 we will explain how to deal with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these sections, 2.1 and 2.2, we conclude how important it is to always look carefully and with a critical view to the unique values of each feature, categorical or numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Duplicated entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define what a duplicate is in the context of our problem. Then we can search for duplicated entries and drop them from the dataset.\n",
    "\n",
    "In our case, each row (observation) corresponds to a person, for which we know an ID (in the index), age, height and gender. Let's define as duplicate the case where two rows or more are exact matches, i.e, the index and the values in all the columns are the same.\n",
    "\n",
    "We can find duplicates using method [`duplicated()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.duplicated.html) and drop duplicated data with [`drop_duplicates()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop_duplicates.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CFLOXRHMDR</th>\n",
       "      <td>88.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FXLJSNLSOG</th>\n",
       "      <td>29.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FWDIVJKGOI</th>\n",
       "      <td>42.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YWEBKQWHRE</th>\n",
       "      <td>25.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YPUQAPSOYJ</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YPUQAPSOYJ</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YPUQAPSOYJ</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YPUQAPSOYJ</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSZQEGTLNK</th>\n",
       "      <td>NaN</td>\n",
       "      <td>162.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRFEFXNGWN</th>\n",
       "      <td>36.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  height  gender\n",
       "CFLOXRHMDR  88.0   163.0  female\n",
       "FXLJSNLSOG  29.0   158.0  female\n",
       "FWDIVJKGOI  42.0   159.0  female\n",
       "YWEBKQWHRE  25.0   179.0    male\n",
       "YPUQAPSOYJ  32.0   169.0    male\n",
       "YPUQAPSOYJ  32.0   169.0    male\n",
       "YPUQAPSOYJ  32.0   169.0    male\n",
       "YPUQAPSOYJ  32.0   169.0    male\n",
       "SSZQEGTLNK   NaN   162.0    male\n",
       "PRFEFXNGWN  36.0   166.0  female"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can you find some duplicates in the 10 first observations?\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 6\n"
     ]
    }
   ],
   "source": [
    "duplicated_mask = data.duplicated(keep='first')\n",
    "\n",
    "print('Number of duplicates:', duplicated_mask.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 6 entries which are duplicated! How do they look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YPUQAPSOYJ</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YPUQAPSOYJ</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YPUQAPSOYJ</th>\n",
       "      <td>32.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XUAJJPLVOI</th>\n",
       "      <td>18.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRMMGYEEPC</th>\n",
       "      <td>21.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZNLRYQHPXJ</th>\n",
       "      <td>25.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  height  gender\n",
       "YPUQAPSOYJ  32.0   169.0    male\n",
       "YPUQAPSOYJ  32.0   169.0    male\n",
       "YPUQAPSOYJ  32.0   169.0    male\n",
       "XUAJJPLVOI  18.0   168.0  female\n",
       "TRMMGYEEPC  21.0   156.0  female\n",
       "ZNLRYQHPXJ  25.0   155.0    male"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[duplicated_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, these are the duplicated observations. This means that for each unique observation above we have at least another one in our dataset.\n",
    "\n",
    "Notice the `keep='first'` in `data.duplicated(...)` means that all the duplicates are flagged as True, except for the first. For example, there are a total of 4 rows with index `YPUQAPSOYJ`, but only 3 in the duplicated_mask.\n",
    "\n",
    "How can we drop all duplicates except for the first occurrence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping duplicates: (200, 3)\n",
      "Shape after dropping duplicates: (194, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape before dropping duplicates: {data.shape}\")\n",
    "data = data.drop_duplicates()\n",
    "print(f\"Shape after dropping duplicates: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes sense, since we deleted 6 duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing Values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values on a dataset is also a very common problem. And as further steps on the data science pipeline can not be compatible with missing values. Because of that, depending on the task you may need to deal with these values before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 How to detect missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find out what are the missing values, we can use method [`isnull`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html), followed by [`sum`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.sum.html) to count how many missing values do we have per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AGFHBQDTEG</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYTVHSPPVG</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSBFYTZEQN</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VYAQBLJKXJ</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLAKTCGBMO</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  height  gender\n",
       "AGFHBQDTEG  False   False   False\n",
       "HYTVHSPPVG  False   False   False\n",
       "DSBFYTZEQN  False   False   False\n",
       "VYAQBLJKXJ   True   False   False\n",
       "BLAKTCGBMO  False   False   False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age       11\n",
       "height     4\n",
       "gender     9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have missing values in all columns. What are the rows with at least one missing value?   \n",
    "To answer this question, we will use the method [any](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSZQEGTLNK</th>\n",
       "      <td>NaN</td>\n",
       "      <td>162.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CWCFROPRFE</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TJQPFEFVVH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PYHWLDVICX</th>\n",
       "      <td>NaN</td>\n",
       "      <td>181.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLRPKGKACD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>185.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSHRBGFOJU</th>\n",
       "      <td>NaN</td>\n",
       "      <td>184.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGMGUJEBNC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>173.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EORSIPDIHA</th>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YZDOYNOXAF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>144.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QXUGUHCOPT</th>\n",
       "      <td>101.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LKEHZFGGTS</th>\n",
       "      <td>49.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBTRPEDHJS</th>\n",
       "      <td>43.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDFQWIHWCH</th>\n",
       "      <td>27.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUCCGRJLXN</th>\n",
       "      <td>20.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GQSNBZIGBL</th>\n",
       "      <td>27.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQYVEHAWSW</th>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NGJOHICWSY</th>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAOAMGUQSX</th>\n",
       "      <td>NaN</td>\n",
       "      <td>144.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LNLAPFIJEQ</th>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JFVZOEGUUA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>208.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KWJJMPVSCP</th>\n",
       "      <td>24.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMZUTCGFYT</th>\n",
       "      <td>21.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VYAQBLJKXJ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>165.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  height  gender\n",
       "SSZQEGTLNK    NaN   162.0    male\n",
       "CWCFROPRFE   22.0     NaN    male\n",
       "TJQPFEFVVH    NaN   182.0     NaN\n",
       "PYHWLDVICX    NaN   181.0  female\n",
       "MLRPKGKACD    NaN   185.0    male\n",
       "TSHRBGFOJU    NaN   184.0  female\n",
       "SGMGUJEBNC    NaN   173.0    male\n",
       "EORSIPDIHA   21.0     NaN    male\n",
       "YZDOYNOXAF    NaN   144.0  female\n",
       "QXUGUHCOPT  101.0   196.0     NaN\n",
       "LKEHZFGGTS   49.0   177.0     NaN\n",
       "EBTRPEDHJS   43.0   147.0     NaN\n",
       "BDFQWIHWCH   27.0   167.0     NaN\n",
       "NUCCGRJLXN   20.0   159.0     NaN\n",
       "GQSNBZIGBL   27.0   197.0     NaN\n",
       "SQYVEHAWSW    NaN   166.0    male\n",
       "NGJOHICWSY   41.0     NaN    male\n",
       "UAOAMGUQSX    NaN   144.0    male\n",
       "LNLAPFIJEQ   37.0     NaN    male\n",
       "JFVZOEGUUA    NaN   208.0  female\n",
       "KWJJMPVSCP   24.0   189.0     NaN\n",
       "LMZUTCGFYT   21.0   153.0     NaN\n",
       "VYAQBLJKXJ    NaN   165.0    male"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each row, we get True if any of the columns is null and False otherwise\n",
    "mask = data.isnull().any(axis=1)\n",
    "\n",
    "# We select the rows for which the mask is True\n",
    "data[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is probably the biggest data problem we generally face. There are several ways to deal with missing values, let's see some of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping missing values**\n",
    "\n",
    "The simplest way to handle missing values is to simply discard the rows with missing values.\n",
    "\n",
    "We can do this using method [`dropna`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html). This method drops all the rows with any missing values from a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping missing values: (194, 3)\n",
      "Shape after dropping missing values: (171, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape before dropping missing values: {data.shape}\")\n",
    "data_no_missing_values = data.dropna()\n",
    "print(f\"Shape after dropping missing values: {data_no_missing_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replacing with the mean or median**\n",
    "\n",
    "For numerical variables with missing values, we can replace the missing values with the mean or median of that variable.\n",
    "\n",
    "It's practically the same to chose the mean or the median, but the median is less sensible to outliers in your variable.\n",
    "\n",
    "For this, we can use method [`fillna`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html), together with value that we think is the best to replace it. The most used are [`mean`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html) or [`median`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.median.html).\n",
    "\n",
    "In our case, let's see how to replace missing values in the `age` column, with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the age column before: 11\n",
      "Missing values in the age column after: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing values in the age column before: {data.age.isnull().sum()}\")\n",
    "age_without_missing_values = data.age.fillna(data.age.median())\n",
    "print(f\"Missing values in the age column after: {age_without_missing_values.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replacing with a new category**\n",
    "\n",
    "For categorical variables, we can replace missing values with a new category, called `unknown`, for instance.\n",
    "\n",
    "This makes it clearer that there is missing information and we don't allow Pandas to trick us with its default of ignoring missing values :)\n",
    "\n",
    "Let's see how we can replace missing values in the `gender` column. We can use method [`fillna`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the gender column before: 9\n",
      "Missing values in the age column after: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing values in the gender column before: {data.gender.isnull().sum()}\")\n",
    "gender_without_missing_values = data.gender.fillna('unknown')\n",
    "print(f\"Missing values in the age column after: {gender_without_missing_values.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female     111\n",
       "male        74\n",
       "unknown      9\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_without_missing_values.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pro tip**\n",
    "\n",
    "We can call [`fillna`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) with a dictionary and handle all these replacements at the same time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values: 0\n"
     ]
    }
   ],
   "source": [
    "data = data.fillna({\n",
    "    'age': data.age.median(),\n",
    "    'height': data.height.median(),\n",
    "    'gender': 'unknown'\n",
    "})\n",
    "\n",
    "print(f\"Number of rows with missing values: {data.isnull().any(axis=1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note**\n",
    "\n",
    "The ways we saw on how to impute missing data are the mechanical ways to handle missing data (_Kaggle style_).\n",
    "However, you can act in a smarter way: understand the real nature of the missing value and act individually; understand why it is missing, and whether it should be missing, or not.\n",
    "\n",
    "For example, if you have missing values in a `height` feature, it might make more sense to replace the missing values according to the `gender` of each observation instead of replacing all missing values by the median of the entire population.\n",
    "\n",
    "You can give it a try and see if the results make more sense!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are masters at cleaning, we can jump into the exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](media/giphy.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
