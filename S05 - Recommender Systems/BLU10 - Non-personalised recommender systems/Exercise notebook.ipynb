{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# BLU10 - Exercises Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.sparse\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "import hashlib # for grading purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q0: Create the ratings matrix (ungraded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58111</th>\n",
       "      <td>423</td>\n",
       "      <td>1206</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1353691236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94054</th>\n",
       "      <td>624</td>\n",
       "      <td>3268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1028111170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97308</th>\n",
       "      <td>652</td>\n",
       "      <td>26843</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1440269953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55435</th>\n",
       "      <td>401</td>\n",
       "      <td>924</td>\n",
       "      <td>5.0</td>\n",
       "      <td>977458816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22437</th>\n",
       "      <td>157</td>\n",
       "      <td>5378</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1323618006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "58111     423     1206     5.0  1353691236\n",
       "94054     624     3268     1.0  1028111170\n",
       "97308     652    26843     5.0  1440269953\n",
       "55435     401      924     5.0   977458816\n",
       "22437     157     5378     2.5  1323618006"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join('data', 'ml-latest-small', 'ratings.csv')\n",
    "data = pd.read_csv(path)\n",
    "# Shuffle Data\n",
    "data = data.sample(10493, random_state=200)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "So, we'll ignore the _timestamp_ and use the _rating_ column as our only source of information for our recommender system. Remember that if you had data of other types of interactions between users and the movies, you could create a metric that incorporates all of that information in the ratings matrix (maybe by averaging them).\n",
    "\n",
    "Keep the following ratings matrix schema in your mind while developing non-personalized systems. These systems rely heavily on the ratings matrix, so maybe also write it on a piece of paper to remember it better!\n",
    "\n",
    "<img align=\"left\" width=\"413\" height=\"239\" src=\"./media/ratings_matrix3.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "In the following exercise you will build the ratings matrix with users as rows and products as columns.\n",
    "\n",
    "Tip: you can use the pandas' _pivot_ function or flex your numpy muscles with the _genfromtxt_ function (it is good for your health!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8a6b8634bc3ef2ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_ratings(original_data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        original_data - the original data with ratings per user and product.\n",
    "        \n",
    "    Returns:\n",
    "        R - (numpy.ndarray) Ratings matrix with the userId, movieId and rating\n",
    "        hint: don't forget to put zeros on places where you do not have ratings\n",
    "    \n",
    "    Extra Hint: Your input is a pandas DataFrame but you want to output an array (use .to_numpy)!\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return data.pivot(index='userId', columns='movieId',values='rating').fillna(0).to_numpy()\n",
    "    \n",
    "\n",
    "R = make_ratings(data)\n",
    "R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We have 657 user and 3628 items.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"We have {R.shape[0]} user and {R.shape[1]} items.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96e5374618fa4f16",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '0825c15053e635376af0a569e8f37cfaef0e1dfce37ae6878517e14e061f13c4'\n",
    "assert hashlib.sha256(str(R.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash_1 = '8ab31b5afaea56114427e1f01b81d001b079a0f59539f6db3f099816ca794055'\n",
    "assert hashlib.sha256(str(R[0].sum()).encode()).hexdigest() == expected_hash_1\n",
    "\n",
    "expected_hash_2 = 'b5967724d1225caa9c6af28a9b333a29e6d5c11a24e9d381acf5c3377524b776'\n",
    "assert hashlib.sha256(str(R[:,0].sum()).encode()).hexdigest() == expected_hash_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q1: Convert the Ratings Matrix to a Sparse Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "In this exercise, convert the ratings matrix to a sparse row representation. \n",
    "\n",
    "Hint: Remember what we have done with scipy library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c0c272ba37054416",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def get_csr(orig_matrix):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        orig_matrix - The original Ratings Matrix.\n",
    "    \n",
    "    Returns\n",
    "        H_ - The Compressed Sparse Row Matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return csr_matrix(orig_matrix)\n",
    "    \n",
    "sparse_mat = get_csr(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-35b3a4b1f0a76185",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'e33275c9e0741880dc0334b76fb8cb17e27020dec75dda07ab221dbb97277d30'\n",
    "assert hashlib.sha256(str(sparse_mat).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q2: What is the density score of this matrix?\n",
    "\n",
    "In this exercise, let's understand the density score (this is, the fraction of rows that are non zero in the original rating matrix).\n",
    "\n",
    "Calculate the get_density_score function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49adf0f3c0101526",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004402172180184897"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_density_score(orig_matrix):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        orig_matrix - Ratings Matrix\n",
    "        \n",
    "    Returns:\n",
    "        dense_score - (float) Density Score of matrix Orig Matrix. \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # YOUR CODE HERE\n",
    "    return orig_matrix[orig_matrix.nonzero()].size / orig_matrix.size\n",
    "    \n",
    "dense_score = get_density_score(R)\n",
    "dense_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0792440f45999d40",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(dense_score,0.004,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Density Score is 0.004402172180184897.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The Density Score is {dense_score}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q3: Popular Items - What are the Top-3 Most Rated items?\n",
    "More ratings give us the current trends but not necessarily the best suggestions - but let's check Items that have more ratings given.\n",
    "\n",
    "In this exercise you will have to retrieve the indexes of the products so you may need to recreate the ratings matrix as a dataframe or come up with another creative solution!\n",
    "\n",
    "Return the product IDs from the product with most ratings to the lowest.\n",
    "\n",
    "**Hint: To get the ID's it's easier if you work with the original data frame other than the rating matrix!**\n",
    "**Remember the pandas pivot method! ;)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9ce05dd01331575e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[318, 356, 296]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top3items(original_df, n):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        original_df - Original Data Frame with ratings\n",
    "        n - Number of Top-n items to retrieve\n",
    "        \n",
    "    Returns\n",
    "        top_ids - (list) list of product ids of  \n",
    "        the top-n most rated items\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return list(original_df.pivot(index='userId',columns='movieId',values='rating').count(axis=0).sort_values(ascending= False).index[:n])\n",
    "\n",
    "most_wanted = top3items(data, 3)\n",
    "\n",
    "most_wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ae4661f44fc09de8",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '3f54e8a66e4924557721acdcb1d40e4399376f780ce6d2b11f48931fc5e1376f'\n",
    "assert hashlib.sha256(str(most_wanted).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q4: Influencers - What are the Top-5 Most Active Users?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Now let's do the following for users! Return the top 5 most active users - this is, the ones that have rated most products. \n",
    "\n",
    "Return the user IDs from the users with most ratings to the lowest ones (but only the top 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1559bfc72b8eaf4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[547, 564, 15, 624, 73]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_influencers(original_df, n):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        original_df - Original DataFrame with ratings\n",
    "        n - number of top-n most active users\n",
    "        \n",
    "    Returns\n",
    "        influencers - (list) list of \n",
    "        ids of the top-n most active users\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    influencers=list(original_df.pivot(index='movieId',columns='userId',values='rating').count(axis=0).sort_values(ascending= False).index[:5])\n",
    "    \n",
    "    return influencers\n",
    "\n",
    "influencers = get_influencers(data, 5)\n",
    "\n",
    "influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2cd4b77837e74779",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '2cbf47fd3da8e22be1bff24eb3e2ad0b99b8992d870e7a5ea4f21880588accc6'\n",
    "assert hashlib.sha256(str(influencers).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Elite - What are the Top-7 Better Rated Items (On Average)?\n",
    "\n",
    "Since this can be biased by a low number of ratings, we need items to have more than 10 ratings. Use average to obtain the ids of the top average rated products. Return the product ID from the highest rated to the lowest rated item.\n",
    "\n",
    "Hint: In this exercise and to filter the movies by rating, it may be easier to use the original data and then reconstruct the ratings matrix!\n",
    "<br>\n",
    "Hint 2: Don't forget that we are asking for the **top** rated items so you have to sort your average ratings in some way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62b63f8f75bd5d58",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[527, 2959, 50, 318, 1193, 1219, 2571]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def elite(original_data, n, k):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        original_data - The original dataframe with ratings.\n",
    "        n - Top-n items\n",
    "        k - Mininum number of ratings\n",
    "        \n",
    "    Returns\n",
    "        best_items - (list) list of ids of top-n best mean rated items.\n",
    "        Your indices should refer only to items with more than k ratings (subset of original matrix).\n",
    "    \"\"\"\n",
    "    \n",
    "    R_ = original_data.pivot(index='userId',columns='movieId',values='rating').fillna(0)\n",
    "    \n",
    "    count_ratings = np.greater(R_, 0).sum(axis=0)\n",
    "    \n",
    "    R_[R_ == 0] = np.NaN\n",
    "    mean_ratings = np.nanmean(R_, axis=0)\n",
    "    \n",
    "   \n",
    "    df = pd.DataFrame([pd.Series(count_ratings),pd.Series(mean_ratings, index=count_ratings.index)]).T\n",
    "    best_items = list(df[df[0]>k].sort_values(by=[1], ascending= False).index[:n])\n",
    "    \n",
    "    return best_items\n",
    "    \n",
    "best_items = elite(data, 7, 10)\n",
    "\n",
    "best_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3e673279793bc5d4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '0ed83bd0067fb63b2c591d0039829a3a9bc6887a7bb8f076bc15f6e6944e9216'\n",
    "assert hashlib.sha256(str(best_items).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Q6: Apriori - What are the 5 most common 2-piece itemsets?\n",
    "We define \"common itemsets\" as at least 2 different items that are usually rated together at least by 0.5% of the population (erheeem support!).\n",
    "Show your results sorted by support in descending way.\n",
    "\n",
    "Hint: Check the mlxtend documentation for help: http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dff47ecd831f9ca3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0.010654</td>\n",
       "      <td>(268, 189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0.010654</td>\n",
       "      <td>(229, 279)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>0.009132</td>\n",
       "      <td>(172, 229)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>0.009132</td>\n",
       "      <td>(229, 342)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0.009132</td>\n",
       "      <td>(177, 155)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      support    itemsets\n",
       "834  0.010654  (268, 189)\n",
       "846  0.010654  (229, 279)\n",
       "823  0.009132  (172, 229)\n",
       "847  0.009132  (229, 342)\n",
       "813  0.009132  (177, 155)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getBundlesSolution(original_data, n=None, min_support=None, top=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        original_data: Original data frame with ratings.\n",
    "        n: Number of items in commonset\n",
    "        min_support: Minimum percentage of users that contains the itemset\n",
    "        top: Number of most common itemsets\n",
    "        \n",
    "    Return\n",
    "        df: the return dataframe should have two columns [\"support\", \"itemsets\"],\n",
    "            with the support percentage and the itemsets.\n",
    "    \"\"\"\n",
    "    R = original_data.pivot(index='userId',columns='movieId',values='rating').fillna(0)\n",
    "    R_ = pd.DataFrame(R > 0)\n",
    "    \n",
    "    apriori_mt = apriori(R_, min_support)\n",
    "    apriori_mt_n = apriori_mt[apriori_mt.itemsets.map(len)==n]\n",
    "    return apriori_mt_n.sort_values(by='support', ascending = False)[:top]\n",
    " \n",
    "\n",
    "df = getBundlesSolution(data, n=2, min_support=0.005, top=5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-404e9c98f711743d",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'f7441550a0ca5274581d023417c99540e3a8a4cca68824a87cbe6d95c07742ea'\n",
    "assert hashlib.sha256(str(df.shape).encode()).hexdigest() == expected_hash\n",
    "\n",
    "np.testing.assert_almost_equal(df.iloc[0,0],0.011,3)\n",
    "\n",
    "np.testing.assert_almost_equal(df.iloc[4,0],0.009,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
